"""
Hybrid Search - Option 4: Parallel Execution with Query Expansion (Async)

ì „ëµ:
1. LLMìœ¼ë¡œ í‚¤ì›Œë“œ 3ê°œ ì¶”ì¶œ (ì´ˆê²½ëŸ‰)
2. 3ê°œ DB ì™„ì „ ë³‘ë ¬ ì‹¤í–‰ (asyncio.gather)
3. RRF ê°€ì¤‘ì¹˜ ì¡°ì ˆ (PG:1.0, Neo4j:0.8, Milvus:0.3)
4. canonical_name í†µì¼ ê²€ìƒ‰

ì¥ì : ì™„ì „ ë³‘ë ¬, LLM ìµœì†Œí™”, ëˆ„ë½ ì—†ìŒ
"""
from typing import List, Dict, Any, Optional
from sqlalchemy.ext.asyncio import AsyncSession
from sqlalchemy import select
import asyncio
import logging
import re

from database.models.maple_dictionary import MapleDictionary
from src.retrievers.db_searcher import MapleDBSearcher
from src.retrievers.milvus_retriever import MilvusRetriever
from src.retrievers.neo4j_searcher import Neo4jSearcher
from src.agents.router_agent import RouterAgent
from src.utils.keyword_extractor import MapleKeywordExtractor

logger = logging.getLogger(__name__)


class HybridSearcher:
    """
    Intent ê¸°ë°˜ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ + Plan Execution
    
    ì „ëµ:
    1. Router Agentë¡œ Intent ë¶„ì„ & Plan ìˆ˜ë¦½
       - Queryì˜ ì˜ë„ íŒŒì•…
       - Multi-step ê²€ìƒ‰ ì „ëµ ìƒì„±
    
    2. Plan ì‹¤í–‰ (NEW!)
       - SQL_DB â†’ PostgreSQL (í‚¤ì›Œë“œ ê²€ìƒ‰)
       - GRAPH_DB â†’ Neo4j (ê´€ê³„ ì¶”ì ) [ì¤€ë¹„ì¤‘]
       - VECTOR_DB â†’ Milvus (ì˜ë¯¸ ê²€ìƒ‰)
    
    3. ê²°ê³¼ ë³‘í•© & ë­í‚¹
       - ì—¬ëŸ¬ Stepì˜ ê²°ê³¼ë¥¼ í†µí•©
       - ì ìˆ˜ ê¸°ë°˜ ì •ë ¬
    """
    
    def __init__(
        self, 
        db: AsyncSession,
        use_milvus: bool = True,
        use_neo4j: bool = True,
        use_router: bool = True,
        verbose: bool = False
    ):
        self.db = db
        self.use_milvus = use_milvus
        self.use_neo4j = use_neo4j
        self.use_router = use_router
        self.verbose = verbose
        
        # PostgreSQL Searcher
        self.pg_searcher = MapleDBSearcher(db)
        
        # Milvus Searcher (ì˜µì…˜)
        self.milvus_searcher = None
        if use_milvus:
            try:
                self.milvus_searcher = MilvusRetriever()
                logger.info("âœ… Milvus ê²€ìƒ‰ í™œì„±í™”")
            except Exception as e:
                logger.warning(f"âš ï¸ Milvus ì—°ê²° ì‹¤íŒ¨, PostgreSQLë§Œ ì‚¬ìš©: {e}")
                self.use_milvus = False
        
        # Neo4j Searcher (ì˜µì…˜)
        self.neo4j_searcher = None
        if use_neo4j:
            try:
                self.neo4j_searcher = Neo4jSearcher()
                logger.info("âœ… Neo4j ê²€ìƒ‰ í™œì„±í™”")
            except Exception as e:
                logger.warning(f"âš ï¸ Neo4j ì—°ê²° ì‹¤íŒ¨: {e}")
                self.use_neo4j = False
        
        # Router Agent (ì˜µì…˜)
        self.router = None
        if use_router:
            try:
                self.router = RouterAgent(verbose=False)
                logger.info("âœ… Router Agent í™œì„±í™”")
            except Exception as e:
                logger.warning(f"âš ï¸ Router Agent ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                self.use_router = False
        
        # Keyword Extractor (Kiwi í˜•íƒœì†Œ ë¶„ì„ + ë™ì˜ì–´ ì¹˜í™˜)
        try:
            self.keyword_extractor = MapleKeywordExtractor(db)
            logger.info("âœ… Kiwi Keyword Extractor í™œì„±í™”")
        except Exception as e:
            logger.warning(f"âš ï¸ Kiwi ì´ˆê¸°í™” ì‹¤íŒ¨, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©: {e}")
            self.keyword_extractor = None
    
    async def search(
        self,
        query: str,
        category: Optional[str] = None,
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Option 4: Parallel Execution with Query Expansion
        
        ì „ëµ:
        1. LLMìœ¼ë¡œ í‚¤ì›Œë“œ 3ê°œ ì¶”ì¶œ (ì´ˆê²½ëŸ‰)
        2. 3ê°œ DB ì™„ì „ ë³‘ë ¬ ì‹¤í–‰
        3. RRF ê°€ì¤‘ì¹˜ ì¡°ì ˆ (PG:1.0, Neo4j:0.8, Milvus:0.3)
        
        Args:
            query: ê²€ìƒ‰ ì¿¼ë¦¬
            category: ë¯¸ì‚¬ìš©
            limit: ìµœëŒ€ ê²°ê³¼ ê°œìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (RRF ê°€ì¤‘ì¹˜ ì ìˆ˜ ìˆœ)
        """
        if self.verbose:
            print(f"\nğŸ” Option 4 Search: '{query}'")
        
        # Step 1: LLMìœ¼ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ (ì´ˆê²½ëŸ‰)
        keywords = await self._extract_keywords_llm(query)
        
        if self.verbose:
            print(f"   ğŸ”‘ ì¶”ì¶œ í‚¤ì›Œë“œ: {keywords}")
        
        # Step 2: 3ê°œ DB ì™„ì „ ë³‘ë ¬ ì‹¤í–‰
        if self.verbose:
            print(f"   âš¡ PostgreSQL + Milvus + Neo4j ì™„ì „ ë³‘ë ¬...")
        
        pg_task = self._search_by_keywords_pg(keywords, limit)
        milvus_task = self._search_by_keywords_milvus(keywords, limit) if self.use_milvus else asyncio.sleep(0)
        neo4j_task = self._search_by_keywords_neo4j(keywords, limit) if self.use_neo4j else asyncio.sleep(0)
        
        pg_results, milvus_results, neo4j_results = await asyncio.gather(
            pg_task, milvus_task, neo4j_task
        )
        
        if not self.use_milvus:
            milvus_results = []
        if not self.use_neo4j:
            neo4j_results = []
        
        if self.verbose:
            print(f"   PostgreSQL: {len(pg_results)}ê°œ")
            print(f"   Milvus: {len(milvus_results)}ê°œ")
            print(f"   Neo4j: {len(neo4j_results)}ê°œ")
        
        # sources í•„ë“œ ì¶”ê°€
        for r in pg_results:
            if "sources" not in r:
                r["sources"] = ["PostgreSQL"]
        for r in milvus_results:
            if "sources" not in r:
                r["sources"] = ["Milvus"]
        for r in neo4j_results:
            if "sources" not in r:
                r["sources"] = ["Neo4j"]
        
        # Step 3: RRF ê°€ì¤‘ì¹˜ ì ìš© (PG:1.0, Neo4j:0.8, Milvus:0.3)
        results_by_source = {
            "PostgreSQL": pg_results,
            "Milvus": milvus_results,
            "Neo4j": neo4j_results
        }
        
        final_results = self._apply_rrf_weighted(
            results_by_source,
            weights={"PostgreSQL": 1.0, "Neo4j": 0.8, "Milvus": 0.3}
        )[:limit]
        
        if self.verbose:
            print(f"   ğŸ“Š ìµœì¢…: {len(final_results)}ê°œ\n")
        
        return final_results
    
    async def execute_plan(
        self,
        original_query: str,
        router_result: Dict[str, Any],
        limit: int = 10
    ) -> List[Dict[str, Any]]:
        """
        Routerì˜ Planì„ ì‹¤ì œë¡œ ì‹¤í–‰ (async/await ë³‘ë ¬ + ìˆœì°¨ í•˜ì´ë¸Œë¦¬ë“œ)
        + RRF (Reciprocal Rank Fusion) ì ìš©
        
        ì „ëµ:
        1. Planì„ ë°°ì¹˜ë¡œ ê·¸ë£¹í™”
           - SQL_DB, VECTOR_DBëŠ” ë…ë¦½ì  â†’ ë³‘ë ¬ ì‹¤í–‰
           - GRAPH_DBëŠ” ì´ì „ ê²°ê³¼ í•„ìš” â†’ ìƒˆ ë°°ì¹˜ ì‹œì‘
        2. ê° ë°°ì¹˜ë¥¼ asyncio.gatherë¡œ ë³‘ë ¬ ì‹¤í–‰
        3. ë°°ì¹˜ ê°„ì—ëŠ” ìˆœì°¨ ì‹¤í–‰ (ì˜ì¡´ì„± ë³´ì¥)
        4. RRFë¡œ ë‹¤ì¤‘ ì†ŒìŠ¤ ê²°ê³¼ ìœµí•©
        
        Args:
            original_query: ì›ë³¸ ì§ˆë¬¸
            router_result: Routerê°€ ìƒì„±í•œ Plan
            limit: ìµœëŒ€ ê²°ê³¼ ê°œìˆ˜
            
        Returns:
            ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (RRF ì ìˆ˜ ìˆœ)
        """
        plan = router_result.get("plan", [])
        
        if not plan:
            logger.warning("Planì´ ë¹„ì–´ìˆìŒ, ê¸°ë³¸ ê²€ìƒ‰ìœ¼ë¡œ í´ë°±")
            return await self._postgres_search(original_query, None, limit)
        
        if self.verbose:
            print(f"\n   ğŸ“‹ Plan ì‹¤í–‰ (ë³‘ë ¬ ìµœì í™” + RRF):")
        
        # Planì„ ë°°ì¹˜ë¡œ ê·¸ë£¹í™”
        batches = self._group_plan_into_batches(plan)
        
        if self.verbose:
            print(f"      ë°°ì¹˜: {len(batches)}ê°œ (ë³‘ë ¬ ê°€ëŠ¥í•œ Stepë¼ë¦¬ ê·¸ë£¹í™”)")
        
        # ì†ŒìŠ¤ë³„ ê²°ê³¼ ìˆ˜ì§‘ (RRFìš©)
        results_by_source = {
            "PostgreSQL": [],
            "Neo4j": [],
            "Milvus": []
        }
        previous_batch_results = []
        
        # ê° ë°°ì¹˜ ì‹¤í–‰
        for batch_idx, batch in enumerate(batches):
            if self.verbose:
                print(f"\n      === ë°°ì¹˜ {batch_idx + 1}/{len(batches)} ({'ë³‘ë ¬' if len(batch) > 1 else 'ìˆœì°¨'}) ===")
            
            # ë°°ì¹˜ ë‚´ Stepë“¤ì„ ë³‘ë ¬ ì‹¤í–‰
            batch_results = await self._execute_batch_parallel(
                batch, 
                original_query, 
                router_result, 
                previous_batch_results
            )
            
            # ì†ŒìŠ¤ë³„ë¡œ ë¶„ë¥˜
            for result in batch_results:
                sources = result.get("sources", [])
                for source in sources:
                    if source in results_by_source:
                        results_by_source[source].append(result)
            
            # ì´ ë°°ì¹˜ ê²°ê³¼ë¥¼ ë‹¤ìŒ ë°°ì¹˜ì— ì „ë‹¬
            previous_batch_results = batch_results
        
        # RRF ì ìš©
        rrf_results = self._apply_rrf(results_by_source)
        
        if self.verbose:
            print(f"\n   âœ… Plan ì‹¤í–‰ ì™„ë£Œ: ì´ {len(rrf_results)}ê°œ ê²°ê³¼ (RRF ì ìš©)")
        
        return rrf_results[:limit]
    
    def _group_plan_into_batches(self, plan: List[Dict[str, Any]]) -> List[List[Dict[str, Any]]]:
        """
        Planì„ ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ ë°°ì¹˜ë¡œ ê·¸ë£¹í™”
        
        ê·œì¹™:
        1. SQL_DB, VECTOR_DBëŠ” ë…ë¦½ì  â†’ ê°™ì€ ë°°ì¹˜ì— í¬í•¨ ê°€ëŠ¥
        2. GRAPH_DBëŠ” ì´ì „ ê²°ê³¼ í•„ìš” â†’ ìƒˆ ë°°ì¹˜ ì‹œì‘
        
        Args:
            plan: Step ë¦¬ìŠ¤íŠ¸
            
        Returns:
            ë°°ì¹˜ ë¦¬ìŠ¤íŠ¸ (ê° ë°°ì¹˜ëŠ” ë³‘ë ¬ ì‹¤í–‰ ê°€ëŠ¥í•œ Stepë“¤)
        """
        if not plan:
            return []
        
        batches = []
        current_batch = []
        
        for step in plan:
            tool = step.get("tool", "")
            
            # GRAPH_DBëŠ” ì´ì „ ê²°ê³¼ì— ì˜ì¡´ â†’ ë°°ì¹˜ ë¶„ë¦¬
            if tool == "GRAPH_DB":
                # í˜„ì¬ ë°°ì¹˜ê°€ ìˆìœ¼ë©´ ë¨¼ì € ì¶”ê°€
                if current_batch:
                    batches.append(current_batch)
                    current_batch = []
                # GRAPH_DBëŠ” ë³„ë„ ë°°ì¹˜
                batches.append([step])
            else:
                # SQL_DB, VECTOR_DBëŠ” ê°™ì€ ë°°ì¹˜ì— ì¶”ê°€
                current_batch.append(step)
        
        # ë§ˆì§€ë§‰ ë°°ì¹˜ ì¶”ê°€
        if current_batch:
            batches.append(current_batch)
        
        return batches
    
    async def _execute_batch_parallel(
        self,
        batch: List[Dict[str, Any]],
        original_query: str,
        router_result: Dict[str, Any],
        previous_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        ë°°ì¹˜ ë‚´ Stepë“¤ì„ ë³‘ë ¬ ì‹¤í–‰ (async/await)
        
        Args:
            batch: ë³‘ë ¬ ì‹¤í–‰í•  Step ë¦¬ìŠ¤íŠ¸
            original_query: ì›ë³¸ ì§ˆë¬¸
            router_result: Router ê²°ê³¼
            previous_results: ì´ì „ ë°°ì¹˜ ê²°ê³¼
            
        Returns:
            ë°°ì¹˜ ì‹¤í–‰ ê²°ê³¼
        """
        batch_results = []
        
        # ë‹¨ì¼ Step â†’ ê·¸ëƒ¥ ì‹¤í–‰
        if len(batch) == 1:
            step = batch[0]
            step_num = step.get("step", 0)
            tool = step.get("tool", "")
            reason = step.get("reason", "")
            
            if self.verbose:
                print(f"      [{step_num}] {tool}: {reason}")
            
            results = await self._execute_single_step(step, original_query, router_result, previous_results)
            
            if self.verbose:
                print(f"         â†’ {len(results)}ê°œ ë°œê²¬")
            
            return results
        
        # ë‹¤ì¤‘ Step â†’ async ë³‘ë ¬ ì‹¤í–‰
        if self.verbose:
            for step in batch:
                print(f"      [{step.get('step', 0)}] {step.get('tool', '')}: {step.get('reason', '')}")
        
        # asyncio.gatherë¡œ ë³‘ë ¬ ì‹¤í–‰
        tasks = [
            self._execute_single_step(step, original_query, router_result, previous_results)
            for step in batch
        ]
        
        try:
            # ëª¨ë“  íƒœìŠ¤í¬ ë³‘ë ¬ ì‹¤í–‰
            results_list = await asyncio.gather(*tasks, return_exceptions=True)
            
            # ê²°ê³¼ ìˆ˜ì§‘
            for idx, (step, results) in enumerate(zip(batch, results_list)):
                if isinstance(results, Exception):
                    logger.error(f"Step {step.get('step', 0)} ì‹¤í–‰ ì‹¤íŒ¨: {results}")
                else:
                    batch_results.extend(results)
                    
                    if self.verbose:
                        print(f"         [{step.get('step', 0)}] â†’ {len(results)}ê°œ ë°œê²¬")
        
        except Exception as e:
            logger.error(f"ë°°ì¹˜ ë³‘ë ¬ ì‹¤í–‰ ì‹¤íŒ¨: {e}")
        
        return batch_results
    
    async def _execute_single_step(
        self,
        step: Dict[str, Any],
        original_query: str,
        router_result: Dict[str, Any],
        previous_results: List[Dict[str, Any]]
    ) -> List[Dict[str, Any]]:
        """
        ë‹¨ì¼ Step ì‹¤í–‰ (async)
        
        Args:
            step: ì‹¤í–‰í•  Step
            original_query: ì›ë³¸ ì§ˆë¬¸
            router_result: Router ê²°ê³¼
            previous_results: ì´ì „ ê²°ê³¼
            
        Returns:
            Step ì‹¤í–‰ ê²°ê³¼
        """
        tool = step.get("tool", "")
        query = step.get("query", "")
        
        try:
            if tool == "SQL_DB":
                return await self._execute_sql_db_step(original_query, query, router_result)
                
            elif tool == "GRAPH_DB":
                # ì´ì „ ê²°ê³¼ë¡œ ì¿¼ë¦¬ ì¡°ì •
                adjusted_query = self._adjust_graph_query(query, previous_results)
                results = await self._execute_graph_db_step(original_query, adjusted_query, router_result)
                # PostgreSQLë¡œ ë³´ì¶©
                return await self._enrich_graph_results(results)
                
            elif tool == "VECTOR_DB":
                return await self._execute_vector_db_step(original_query, query, router_result)
            else:
                logger.warning(f"ì•Œ ìˆ˜ ì—†ëŠ” Tool: {tool}")
                return []
                
        except Exception as e:
            logger.error(f"Step ì‹¤í–‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _adjust_graph_query(
        self,
        query: str,
        previous_results: List[Dict[str, Any]]
    ) -> str:
        """
        GRAPH_DB ì¿¼ë¦¬ë¥¼ ì´ì „ Step ê²°ê³¼ë¡œ ì¡°ì •
        
        Args:
            query: ì›ë³¸ ì¿¼ë¦¬ (ì˜ˆ: "ë‹¤í¬ë¡œë“œ â†’ ìœ„ì¹˜ â†’ MAP")
            previous_results: ì´ì „ Stepì˜ ê²€ìƒ‰ ê²°ê³¼
            
        Returns:
            ì¡°ì •ëœ ì¿¼ë¦¬
        """
        if not previous_results:
            return query
        
        try:
            # ì´ì „ Stepì—ì„œ ì°¾ì€ ì²« ë²ˆì§¸ ì—”í‹°í‹° ì´ë¦„ ì¶”ì¶œ
            first_result = previous_results[0]
            data = first_result.get("data", {})
            canonical_name = data.get("canonical_name")
            
            if not canonical_name:
                return query
            
            # ì¿¼ë¦¬ì—ì„œ ì²« ë²ˆì§¸ ë‹¨ì–´(ì—”í‹°í‹° ì´ë¦„)ë¥¼ ì‹¤ì œ ì°¾ì€ ì´ë¦„ìœ¼ë¡œ ì¹˜í™˜
            # ì˜ˆ: "ë‹¤í¬ë¡œë“œ â†’ ìœ„ì¹˜ â†’ MAP"
            parts = query.split("â†’")
            if len(parts) >= 2:
                # ì²« ë²ˆì§¸ ë¶€ë¶„ì„ ì‹¤ì œ ì°¾ì€ ì—”í‹°í‹°ë¡œ êµì²´
                parts[0] = canonical_name
                adjusted_query = " â†’ ".join(parts)
                
                if self.verbose and adjusted_query != query:
                    print(f"         ì¿¼ë¦¬ ì¡°ì •: {query} â†’ {adjusted_query}")
                
                return adjusted_query
            
            return query
            
        except Exception as e:
            logger.warning(f"ì¿¼ë¦¬ ì¡°ì • ì‹¤íŒ¨: {e}")
            return query
    
    async def _execute_sql_db_step(
        self,
        original_query: str,
        step_query: str,
        router_result: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        SQL_DB Step ì‹¤í–‰ (PostgreSQL ê²€ìƒ‰, async)
        
        í•µì‹¬: ì§ˆë¬¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ì—¬ ê²€ìƒ‰
        âš ï¸ ì¹´í…Œê³ ë¦¬ í•„í„°ë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³  ì „ì²´ ê²€ìƒ‰ (Routerì˜ ì˜¤íŒë‹¨ ë°©ì§€)
        """
        # í‚¤ì›Œë“œ ì¶”ì¶œ (ì¡°ì‚¬ ì œê±° + ë¶ˆìš©ì–´ ì œê±°)
        keywords = await self._extract_keywords(original_query)
        
        if self.verbose:
            print(f"         í‚¤ì›Œë“œ: {keywords}")
        
        results = []
        
        # ê° í‚¤ì›Œë“œë¡œ ê²€ìƒ‰ (ìˆœì°¨ì ìœ¼ë¡œ, ì¹´í…Œê³ ë¦¬ í•„í„° ì—†ì´ ì „ì²´ ê²€ìƒ‰)
        for keyword in keywords:
            try:
                keyword_results = await self.pg_searcher.search(
                    keyword,
                    category=None,  # âœ… ì¹´í…Œê³ ë¦¬ í•„í„° ì œê±° - ì „ì²´ ê²€ìƒ‰
                    limit=5
                )
                
                # sources í•„ë“œ ì¶”ê°€!
                for result in keyword_results:
                    if "sources" not in result:
                        result["sources"] = ["PostgreSQL"]
                
                results.extend(keyword_results)
            except Exception as e:
                logger.warning(f"í‚¤ì›Œë“œ '{keyword}' ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                continue
        
        return results
    
    async def _execute_graph_db_step(
        self,
        original_query: str,
        step_query: str,
        router_result: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        GRAPH_DB Step ì‹¤í–‰ (Neo4j ê´€ê³„ ê²€ìƒ‰, async)
        
        step_query ë¶„ì„:
        - "NPC â†’ MAP" â†’ NPC ìœ„ì¹˜ ì°¾ê¸°
        - "MONSTER â†’ MAP" â†’ ëª¬ìŠ¤í„° ì¶œí˜„ ìœ„ì¹˜
        - "ITEM â†’ NPC" â†’ ì•„ì´í…œ íŒë§¤ NPC
        - "ITEM â†’ MONSTER" â†’ ì•„ì´í…œ ë“œë ëª¬ìŠ¤í„°
        - "MAP â†’ MAP" â†’ ë§µ ì—°ê²°
        """
        if not self.use_neo4j or not self.neo4j_searcher:
            logger.info("Neo4j ê²€ìƒ‰ ë¹„í™œì„±í™”")
            return []
        
        # step_queryì—ì„œ ê´€ê³„ ìœ í˜• ì¶”ì¶œ
        step_query_lower = step_query.lower()
        
        # step_queryì—ì„œ ì—”í‹°í‹° ì´ë¦„ ì¶”ì¶œ (ì˜ˆ: "ë‹¤í¬ë¡œë“œ â†’ ìœ„ì¹˜ â†’ MAP")
        entity_name = None
        if "â†’" in step_query:
            parts = step_query.split("â†’")
            entity_name = parts[0].strip()
            
            # ì¹´í…Œê³ ë¦¬ ì ‘ë‘ì‚¬ ì œê±° (MAP, MONSTER, NPC, ITEM ë“±)
            category_prefixes = ["MAP ", "MONSTER ", "NPC ", "ITEM "]
            for prefix in category_prefixes:
                if entity_name.startswith(prefix):
                    entity_name = entity_name[len(prefix):].strip()
                    break
        
        # í‚¤ì›Œë“œë¡œ ì—”í‹°í‹° ì´ë¦„ ì¶”ì¶œ (fallback)
        keywords = await self._extract_keywords(original_query)
        
        # step_queryì—ì„œ ì¶”ì¶œí•œ ì—”í‹°í‹°ê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš© (ì¤‘ë³µ ì œê±°)
        if entity_name:
            if entity_name not in keywords:
                keywords = [entity_name] + keywords
            else:
                # ì´ë¯¸ ìˆìœ¼ë©´ ì•ìœ¼ë¡œ ì´ë™
                keywords.remove(entity_name)
                keywords = [entity_name] + keywords
        
        if self.verbose:
            print(f"         GRAPH_DB step_query: {step_query}")
            print(f"         Keywords: {keywords}")
        
        results = []
        
        # NPC ê´€ë ¨ ê²€ìƒ‰
        if "npc" in step_query_lower and "map" in step_query_lower:
            # Case 1: NPC ìœ„ì¹˜ ê²€ìƒ‰ ("NPCê°€ ì–´ë””ì— ìˆëŠ”ì§€")
            if any(word in step_query_lower for word in ["ìœ„ì¹˜", "ì–´ë””", "ìˆëŠ”ì§€"]) and \
               any(word in original_query for word in ["ì–´ë””", "ìœ„ì¹˜"]):
                for keyword in keywords:
                    npc_results = await self.neo4j_searcher.find_npc_location(keyword)
                    results.extend(self._format_graph_results(npc_results, "graph_npc_location"))
            
            # Case 2: MAP â†’ NPC ("ë§µì— ì–´ë–¤ NPCê°€ ìˆëŠ”ì§€")
            else:
                # PostgreSQLì—ì„œ MAP ê²€ìƒ‰ í›„ resident_npcs í™œìš©
                for keyword in keywords:
                    if keyword not in ["MAP", "NPC", "MONSTER", "ITEM"] and len(keyword) >= 2:
                        try:
                            pg_results = await self.pg_searcher.search(keyword, category="MAP", limit=3)
                            # sources í•„ë“œ ì¶”ê°€
                            for result in pg_results:
                                if "sources" not in result:
                                    result["sources"] = ["PostgreSQL"]
                            results.extend(pg_results)
                        except Exception as e:
                            logger.warning(f"MAP NPC ê²€ìƒ‰ ì‹¤íŒ¨ ({keyword}): {e}")
        
        # ëª¬ìŠ¤í„° ìœ„ì¹˜ ê²€ìƒ‰
        elif "monster" in step_query_lower and "map" in step_query_lower:
            for keyword in keywords:
                monster_results = await self.neo4j_searcher.find_monster_locations(keyword)
                results.extend(self._format_graph_results(monster_results, "graph_monster_location"))
        
        # ì•„ì´í…œ íŒë§¤ NPC ê²€ìƒ‰
        elif "item" in step_query_lower and "npc" in step_query_lower:
            # "íŒë§¤" ë˜ëŠ” "sell" í‚¤ì›Œë“œ
            if any(word in step_query_lower for word in ["íŒë§¤", "sell", "êµ¬ë§¤", "buy", "ì‚¬"]):
                for keyword in keywords:
                    seller_results = await self.neo4j_searcher.find_item_sellers(keyword)
                    results.extend(self._format_graph_results(seller_results, "graph_item_seller"))
        
        # ì•„ì´í…œ ë“œë ëª¬ìŠ¤í„° ê²€ìƒ‰
        elif any(word in step_query_lower for word in ["ë“œë", "drop", "ë–¨ì–´", "ë‚˜ì™€", "ë‚˜ì˜¤"]):
            # "ë“œë", "ëª¬ìŠ¤í„°" í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ë“œë ê²€ìƒ‰
            if "ëª¬ìŠ¤í„°" in step_query_lower or "monster" in step_query_lower:
                for keyword in keywords:
                    dropper_results = await self.neo4j_searcher.find_item_droppers(keyword)
                    results.extend(self._format_graph_results(dropper_results, "graph_item_dropper"))
        
        # ë§µ ì—°ê²° ê²€ìƒ‰
        elif "map" in step_query_lower and any(word in step_query_lower for word in ["ê²½ë¡œ", "connect", "ì´ë™", "ê°€ëŠ”"]):
            for keyword in keywords:
                map_results = await self.neo4j_searcher.find_map_connections(keyword)
                results.extend(self._format_graph_results(map_results, "graph_map_connection"))
        
        # âœ… MAP ê²€ìƒ‰ (resident_npcs, resident_monstersëŠ” PostgreSQLì— ìˆìŒ)
        # "MAP â†’ ì»¤ë‹ì‹œí‹°", "ì»¤ë‹ì‹œí‹°ì— ì–´ë–¤ NPC" ë“±
        else:
            # keywordsì— ë§µ ì´ë¦„ì´ ìˆìœ¼ë©´ PostgreSQL ì§ì ‘ ê²€ìƒ‰
            for keyword in keywords:
                if keyword not in ["MAP", "NPC", "MONSTER", "ITEM"] and len(keyword) >= 2:
                    try:
                        # MAP ìš°ì„  ê²€ìƒ‰
                        if "map" in step_query_lower or "ë§µ" in step_query_lower or \
                           any(word in original_query for word in ["ì–´ë–¤", "ìˆì–´", "ì£¼ë¯¼"]):
                            pg_results = await self.pg_searcher.search(keyword, category="MAP", limit=3)
                            # sources í•„ë“œ ì¶”ê°€
                            for result in pg_results:
                                if "sources" not in result:
                                    result["sources"] = ["PostgreSQL"]
                            results.extend(pg_results)
                        
                        # ê²°ê³¼ ì—†ìœ¼ë©´ ì „ì²´ ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰
                        if not results:
                            pg_results = await self.pg_searcher.search(keyword, category=None, limit=3)
                            # sources í•„ë“œ ì¶”ê°€
                            for result in pg_results:
                                if "sources" not in result:
                                    result["sources"] = ["PostgreSQL"]
                            results.extend(pg_results)
                            
                    except Exception as e:
                        logger.warning(f"ê²€ìƒ‰ ì‹¤íŒ¨ ({keyword}): {e}")
        
        return results
    
    def _format_graph_results(
        self,
        graph_results: List[Dict[str, Any]],
        match_type: str
    ) -> List[Dict[str, Any]]:
        """
        Neo4j ê²°ê³¼ë¥¼ í†µí•© í¬ë§·ìœ¼ë¡œ ë³€í™˜
        """
        formatted_results = []
        
        for result in graph_results:
            # Neo4j ê²°ê³¼ì—ì„œ ì´ë¦„ ì¶”ì¶œ (ë‹¤ì–‘í•œ í•„ë“œëª… ì§€ì›)
            name = (
                result.get("npc_name") or 
                result.get("map_name") or 
                result.get("monster_name") or 
                result.get("item_name") or 
                result.get("name", "Unknown")
            )
            
            # ID ì¶”ì¶œ
            entity_id = (
                result.get("npc_id") or 
                result.get("map_id") or 
                result.get("monster_id") or 
                result.get("item_id") or 
                result.get("id", "")
            )
            
            formatted_results.append({
                "score": 85.0,  # Graph ê´€ê³„ëŠ” ë†’ì€ ì‹ ë¢°ë„
                "match_type": match_type,
                "sources": ["Neo4j"],
                "data": {
                    "id": entity_id,
                    "canonical_name": name,
                    "category": "RELATION",  # ê´€ê³„ ê²€ìƒ‰ ê²°ê³¼
                    "description": f"{result.get('relation_type', '')} ê´€ê³„",
                    "relation_info": result  # ì›ë³¸ ê´€ê³„ ì •ë³´ ë³´ì¡´
                }
            })
        
        return formatted_results
    
    async def _enrich_graph_results(self, graph_results: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        Neo4j ê²€ìƒ‰ ê²°ê³¼ë¥¼ PostgreSQL detail_dataë¡œ ë³´ì¶© (async)
        
        Neo4jëŠ” ê´€ê³„ë§Œ ì•Œë ¤ì£¼ê³ , ì‹¤ì œ ìƒì„¸ ì •ë³´ëŠ” PostgreSQLì— ìˆìŒ
        ì˜ˆ: Neo4j â†’ "ìŠ¤í¬ì•„"ë¼ëŠ” ì´ë¦„ë§Œ
            PostgreSQL â†’ ìŠ¤í¬ì•„ì˜ level, spawn_maps, drops ë“± ìƒì„¸ ì •ë³´
        
        Args:
            graph_results: Neo4j ê²€ìƒ‰ ê²°ê³¼
            
        Returns:
            detail_dataê°€ ì¶”ê°€ëœ ê²°ê³¼
        """
        enriched = []
        
        for result in graph_results:
            data = result.get("data", {})
            canonical_name = data.get("canonical_name")
            
            if not canonical_name or canonical_name == "Unknown":
                enriched.append(result)
                continue
            
            try:
                # PostgreSQLì—ì„œ ì „ì²´ ì •ë³´ ì¡°íšŒ (async)
                stmt = select(MapleDictionary).where(
                    MapleDictionary.canonical_name == canonical_name
                )
                db_result = await self.db.execute(stmt)
                pg_entity = db_result.scalar_one_or_none()
                
                if pg_entity:
                    # PostgreSQL ë°ì´í„°ë¡œ êµì²´ (ê´€ê³„ ì •ë³´ëŠ” ìœ ì§€)
                    relation_info = data.get("relation_info")
                    result["data"] = pg_entity.to_dict()
                    
                    # ê´€ê³„ ì •ë³´ ì¶”ê°€
                    if relation_info:
                        result["data"]["relation_info"] = relation_info
                    
                    # Category ì—…ë°ì´íŠ¸
                    result["data"]["category"] = str(pg_entity.category).split('.')[-1]
                    
                enriched.append(result)
                
            except Exception as e:
                logger.warning(f"Enrichment ì‹¤íŒ¨ ({canonical_name}): {e}")
                enriched.append(result)
        
        return enriched
    
    async def _execute_vector_db_step(
        self,
        original_query: str,
        step_query: str,
        router_result: Dict[str, Any]
    ) -> List[Dict[str, Any]]:
        """
        VECTOR_DB Step ì‹¤í–‰ (Milvus ì˜ë¯¸ ê²€ìƒ‰, async)
        """
        if not self.use_milvus or not self.milvus_searcher:
            return []
        
        try:
            # ì›ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ì˜ë¯¸ ê²€ìƒ‰
            results = await self.milvus_searcher.search(original_query, top_k=10)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = []
            for result in results:
                formatted_results.append({
                    "score": result.get("score", 0) * 100,
                    "match_type": "vector_db",
                    "sources": ["Milvus"],  # ì¶œì²˜ ì¶”ê°€!
                    "data": result
                })
            
            return formatted_results
            
        except Exception as e:
            logger.error(f"VECTOR_DB ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _extract_keywords(self, query: str) -> List[str]:
        """
        ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ í‚¤ì›Œë“œ ì¶”ì¶œ (Async)
        
        ì „ëµ:
        1. Kiwi í˜•íƒœì†Œ ë¶„ì„ (ìš°ì„ , ì •í™•ë„ ë†’ìŒ)
        2. Fallback: ì •ê·œì‹ + ë¶ˆìš©ì–´ (Kiwi ì‹¤íŒ¨ ì‹œ)
        """
        # Kiwi ì‚¬ìš© ê°€ëŠ¥í•˜ë©´ ìš°ì„  ì‚¬ìš©
        if self.keyword_extractor:
            try:
                return await self.keyword_extractor.extract(query)
            except Exception as e:
                logger.warning(f"Kiwi í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨, Fallback ì‚¬ìš©: {e}")
        
        # Fallback: ê¸°ì¡´ ì •ê·œì‹ ë°©ì‹
        # ì¡°ì‚¬ (í† í° ëì—ì„œ ì œê±°)
        particles = ["ì´", "ê°€", "ì„", "ë¥¼", "ì€", "ëŠ”", "ë„", "ë§Œ", "ì˜", "ì—", "ì„œ", "ë¡œ", "ì™€", "ê³¼"]
        
        # ì ‘ë¯¸ì‚¬ í˜•íƒœ ë¶ˆìš©ì–´ (ë‹¨ì–´ ëì— ë¶™ëŠ” ê²ƒë“¤)
        suffix_stopwords = [
            "í•˜ë ¤ë©´", "í•´ì•¼", "ê°€ì•¼", "ê°€ë ¤ë©´", "í•´ì•¼í•´", "ê°€ì•¼í•´", "í•˜ë©´", "ë˜ë©´",
            "í•˜ê³ ", "ì‹¶ì–´", "ì‹¶ë‹¤", "ì‹¶ìœ¼ë©´", "ë˜ê³ ", "ì›í•´", "ì›í•˜ë‹¤",
            "í•˜ëŠ”", "ìˆëŠ”", "ì—†ëŠ”", "ê°€ëŠ”", "ì˜¤ëŠ”", "ë‚˜ì˜¤ëŠ”",
            "ì–´ìš”", "ì•„ìš”", "í•´ìš”", "ìŠµë‹ˆë‹¤", "ã…‚ë‹ˆë‹¤",
            "ë‚˜ìš”", "í•˜ë‚˜ìš”", "í• ê¹Œìš”", "ìˆë‚˜ìš”", "ì—†ë‚˜ìš”"
        ]
        
        # ì™„ì „ ì¼ì¹˜ ë¶ˆìš©ì–´
        stopwords = {
            # ì˜ë¬¸ì‚¬
            "ì–´ë””", "ì–´ë””ì„œ", "ì–´ë””ë¡œ", "ì–´ë””ì—", "ì–´ë–»ê²Œ", "ì–´ë–¤", "ë­", "ë¬´ì—‡", "ëˆ„êµ¬",
            "ì–¸ì œ", "ì™œ", "ì–¼ë§ˆ", "ëª‡", "ë¬´ìŠ¨",
            # ë™ì‚¬/í˜•ìš©ì‚¬ (ë‹¨ë…)
            "í•˜ë‹¤", "ìˆë‹¤", "ì—†ë‹¤", "ê°€ë‹¤", "ì˜¤ë‹¤", "ë˜ë‹¤", "ë³´ë‹¤", "ì£¼ë‹¤", "ë°›ë‹¤", "ì¡ë‹¤",
            "ê°€ì•¼", "ì™€ì•¼", "í•´ì•¼", "ìˆì–´ì•¼",  # ì¶”ê°€!
            # ì–´ë¯¸/ì¡°ì‚¬
            "í•´", "ìš”", "ë‚˜", "ë‚˜ìš”", "í•˜ë‚˜ìš”",
            # ì¼ë°˜ì–´
            "ê²ƒ", "ìˆ˜", "ë•Œ", "ê³³", "ì¤‘", "ë“±", "ì´ëŸ°", "ì €ëŸ°", "ê·¸ëŸ°", "ì¢€", "ë”"
        }
        
        # í•œê¸€, ì˜ë¬¸, ìˆ«ìë§Œ ì¶”ì¶œ
        tokens = re.findall(r'[ê°€-í£A-Za-z0-9]+', query)
        
        # 1. ì¡°ì‚¬ ì œê±°
        cleaned_tokens = []
        for token in tokens:
            # 3ê¸€ì ì´ìƒì´ê³  ë§ˆì§€ë§‰ ê¸€ìê°€ ì¡°ì‚¬ë©´ ì œê±°
            if len(token) >= 3 and token[-1] in particles:
                cleaned_tokens.append(token[:-1])  # ë§ˆì§€ë§‰ ê¸€ì ì œê±°
            else:
                cleaned_tokens.append(token)
        
        # 2. ë¶ˆìš©ì–´ ì œê±° (ì™„ì „ ì¼ì¹˜ + ì ‘ë¯¸ì‚¬)
        keywords = []
        for token in cleaned_tokens:
            # ì™„ì „ ì¼ì¹˜ ì²´í¬
            if token in stopwords:
                continue
            
            # ì ‘ë¯¸ì‚¬ ì²´í¬ (ì˜ˆ: "ì „ì§í•˜ë ¤ë©´" â†’ "í•˜ë ¤ë©´" ì ‘ë¯¸ì‚¬ ì œê±°)
            is_stopword = False
            for suffix in suffix_stopwords:
                if len(token) > len(suffix) and token.endswith(suffix):
                    # ì ‘ë¯¸ì‚¬ ì œê±° í›„ ë‚¨ì€ ë¶€ë¶„ë§Œ ì¶”ì¶œ
                    core_word = token[:-len(suffix)]
                    if len(core_word) >= 2:  # í•µì‹¬ ë‹¨ì–´ê°€ 2ê¸€ì ì´ìƒ
                        keywords.append(core_word)
                    is_stopword = True
                    break
            
            # ë¶ˆìš©ì–´ ì•„ë‹ˆê³  2ê¸€ì ì´ìƒì´ë©´ ì¶”ê°€
            if not is_stopword and len(token) >= 2:
                keywords.append(token)
        
        # 3. ìˆ«ìë§Œ ìˆëŠ” í† í° ì œì™¸
        keywords = [k for k in keywords if not k.isdigit()]
        
        # 4. ì¤‘ë³µ ì œê±°
        keywords = list(dict.fromkeys(keywords))
        
        # 5. ë¹„ì–´ìˆìœ¼ë©´ ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©
        if not keywords:
            keywords = [query]
        
        return keywords
    
    def _apply_rrf(
        self,
        results_by_source: Dict[str, List[Dict[str, Any]]],
        k: int = 60
    ) -> List[Dict[str, Any]]:
        """
        RRF (Reciprocal Rank Fusion) ì ìš©
        
        ì—¬ëŸ¬ ê²€ìƒ‰ ì†ŒìŠ¤ì˜ ê²°ê³¼ë¥¼ ë­í¬ ê¸°ë°˜ìœ¼ë¡œ ìœµí•©
        
        ê³µì‹: RRF_score(d) = Î£ 1 / (k + rank_i(d))
        
        Args:
            results_by_source: ì†ŒìŠ¤ë³„ ê²°ê³¼
                {
                    "PostgreSQL": [...],
                    "Neo4j": [...],
                    "Milvus": [...]
                }
            k: RRF ìƒìˆ˜ (ê¸°ë³¸ 60)
            
        Returns:
            RRF ì ìˆ˜ë¡œ ì •ë ¬ëœ ê²°ê³¼
        """
        rrf_scores = {}  # entity_id -> RRF score
        entity_data = {}  # entity_id -> ì‹¤ì œ ë°ì´í„°
        
        # ê° ì†ŒìŠ¤ë³„ë¡œ ìˆœìœ„ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°
        for source, results in results_by_source.items():
            if not results:
                continue
            
            # ê²°ê³¼ë¥¼ ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬ (ê° ì†ŒìŠ¤ ë‚´ì—ì„œ)
            sorted_results = sorted(
                results,
                key=lambda x: x.get("score", 0),
                reverse=True
            )
            
            # ìˆœìœ„ ê¸°ë°˜ RRF ì ìˆ˜ ê³„ì‚°
            for rank, result in enumerate(sorted_results):
                data = result.get("data", {})
                entity_id = str(data.get("id", ""))
                
                if not entity_id:
                    continue
                
                # RRF ì ìˆ˜: 1 / (k + rank)
                rrf_score = 1.0 / (k + rank)
                
                # ëˆ„ì 
                if entity_id in rrf_scores:
                    rrf_scores[entity_id] += rrf_score
                else:
                    rrf_scores[entity_id] = rrf_score
                    entity_data[entity_id] = result
        
        # RRF ì ìˆ˜ë¡œ ì •ë ¬
        sorted_entities = sorted(
            rrf_scores.items(),
            key=lambda x: x[1],
            reverse=True
        )
        
        # ìµœì¢… ê²°ê³¼ ìƒì„±
        final_results = []
        for entity_id, rrf_score in sorted_entities:
            result = entity_data[entity_id]
            
            # RRF ì ìˆ˜ë¥¼ 0-100 ìŠ¤ì¼€ì¼ë¡œ ë³€í™˜
            # (ìµœëŒ€ RRF ì ìˆ˜ë¥¼ 100ìœ¼ë¡œ ì •ê·œí™”)
            max_rrf = sorted_entities[0][1] if sorted_entities else 1.0
            normalized_score = (rrf_score / max_rrf) * 100
            
            final_results.append({
                "score": normalized_score,
                "match_type": result.get("match_type", "rrf"),
                "data": result.get("data"),
                "sources": result.get("sources", []),
                "rrf_score": rrf_score  # ì›ë³¸ RRF ì ìˆ˜ë„ ë³´ì¡´
            })
        
        return final_results
    
    async def _postgres_search(
        self,
        query: str,
        category: Optional[str],
        limit: int
    ) -> List[Dict[str, Any]]:
        """PostgreSQL ê²€ìƒ‰ (ë¹ ë¥¸ ì •í™• ë§¤ì¹­, async)"""
        try:
            results = await self.pg_searcher.search(query, category=category, limit=limit)
            return results
        except Exception as e:
            logger.error(f"PostgreSQL ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    async def _milvus_expansion_search(
        self,
        pg_results: List[Dict[str, Any]],
        limit: int
    ) -> List[Dict[str, Any]]:
        """
        Milvus ì—°ê´€ í™•ì¥ ê²€ìƒ‰ (async)
        PostgreSQLì—ì„œ ì°¾ì€ ì—”í‹°í‹°ë“¤ì˜ ì—°ê´€ í•­ëª© ê²€ìƒ‰
        """
        if not self.milvus_searcher:
            return []
        
        milvus_results = []
        seen_ids = set()
        
        # PostgreSQLì—ì„œ ì°¾ì€ TOP 3 ì—”í‹°í‹°ë¡œ í™•ì¥
        for pg_item in pg_results[:3]:
            data = pg_item.get("data", {})
            canonical_name = data.get("canonical_name", "")
            item_id = data.get("id")
            
            if item_id:
                seen_ids.add(str(item_id))
            
            if not canonical_name:
                continue
            
            try:
                # canonical_nameìœ¼ë¡œ Milvus ê²€ìƒ‰
                results = await self.milvus_searcher.search(canonical_name, top_k=5)
                
                # ê²°ê³¼ ì¶”ê°€
                for result in results:
                    result_id = result.get("id")
                    
                    if result_id and result_id not in seen_ids:
                        milvus_results.append({
                            "score": result.get("score", 0) * 50,  # ì ìˆ˜ ì¡°ì •
                            "match_type": "milvus_expansion",
                            "data": result,
                            "source_entity": canonical_name
                        })
                        seen_ids.add(result_id)
                        
                        if len(milvus_results) >= limit:
                            break
                
            except Exception as e:
                logger.warning(f"Milvus í™•ì¥ ê²€ìƒ‰ ì‹¤íŒ¨ ({canonical_name}): {e}")
                continue
            
            if len(milvus_results) >= limit:
                break
        
        return milvus_results
    
    async def _milvus_semantic_search(
        self,
        query: str,
        limit: int
    ) -> List[Dict[str, Any]]:
        """
        Milvus ì˜ë¯¸ ê²€ìƒ‰ (í´ë°±, async)
        ì§ˆë¬¸ ì „ì²´ë¥¼ ì˜ë¯¸ì ìœ¼ë¡œ ê²€ìƒ‰
        """
        if not self.milvus_searcher:
            return []
        
        try:
            # Milvus Q&A ê²€ìƒ‰
            results = await self.milvus_searcher.search(query, top_k=limit)
            
            # ê²°ê³¼ í¬ë§·íŒ…
            formatted_results = []
            for result in results:
                formatted_results.append({
                    "score": result.get("score", 0) * 100,  # ì ìˆ˜ ì¡°ì •
                    "match_type": "milvus_semantic",
                    "data": result
                })
            
            return formatted_results
            
        except Exception as e:
            logger.error(f"Milvus ì˜ë¯¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _merge_results(
        self,
        pg_results: List[Dict[str, Any]],
        milvus_results: List[Dict[str, Any]],
        mode: str = "expansion"
    ) -> List[Dict[str, Any]]:
        """
        PostgreSQL + Milvus ê²°ê³¼ ë³‘í•© (RRF ì ìš©)
        
        Args:
            mode: "expansion" (í™•ì¥) ë˜ëŠ” "fallback" (í´ë°±)
        """
        # RRF ì ìš©
        results_by_source = {
            "PostgreSQL": pg_results,
            "Milvus": milvus_results,
            "Neo4j": []  # ì´ ë©”ì„œë“œì—ì„œëŠ” Neo4j ì—†ìŒ
        }
        
        return self._apply_rrf(results_by_source)
    
    async def _extract_keywords_llm(self, query: str) -> List[str]:
        """
        LLMìœ¼ë¡œ ê²€ìƒ‰ í‚¤ì›Œë“œ 3ê°œ ì¶”ì¶œ (ì´ˆê²½ëŸ‰)
        """
        if not self.router or not self.router.llm:
            # Fallback: Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸° ì‚¬ìš©
            return self._extract_keywords_kiwi(query)
        
        try:
            prompt = f"""ë‹¤ìŒ ì§ˆë¬¸ì—ì„œ ê²€ìƒ‰ì— ì‚¬ìš©í•  í•µì‹¬ í‚¤ì›Œë“œ 3ê°œë¥¼ ì¶”ì¶œí•˜ì„¸ìš”.

ì§ˆë¬¸: {query}

ê·œì¹™:
1. ê³ ìœ ëª…ì‚¬ ìš°ì„  (NPC, ëª¬ìŠ¤í„°, ì•„ì´í…œ, ë§µ ì´ë¦„)
2. ë™ì‘/ê´€ê³„ í‚¤ì›Œë“œ í¬í•¨ (êµ¬ë§¤, íŒë§¤, ìœ„ì¹˜, ì „ì§ ë“±)
3. ì •í™•íˆ 3ê°œ ë‹¨ì–´, ì‰¼í‘œë¡œ êµ¬ë¶„
4. ì˜ˆì‹œ: "ì»¤ë‹ì‹œí‹°, NPC, ì •ì°©"

í‚¤ì›Œë“œ:"""
            
            response = await self.router.llm.ainvoke(prompt)
            keywords_str = response.content.strip()
            keywords = [k.strip() for k in keywords_str.split(",")][:3]
            
            # ìµœì†Œ 1ê°œ ë³´ì¥
            if not keywords:
                keywords = self._extract_keywords_kiwi(query)
            
            return keywords
            
        except Exception as e:
            logger.warning(f"LLM í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}, Fallback ì‚¬ìš©")
            return self._extract_keywords_kiwi(query)
    
    def _extract_keywords_kiwi(self, query: str) -> List[str]:
        """
        Kiwi í˜•íƒœì†Œ ë¶„ì„ê¸°ë¡œ í‚¤ì›Œë“œ ì¶”ì¶œ (LLM ì‹¤íŒ¨ ì‹œ fallback)
        """
        try:
            from kiwipiepy import Kiwi
            kiwi = Kiwi()
            
            # ê³ ìœ ëª…ì‚¬(NNP, NNG) ì¶”ì¶œ
            tokens = kiwi.tokenize(query)
            keywords = []
            
            for token in tokens:
                # ê³ ìœ ëª…ì‚¬, ì¼ë°˜ëª…ì‚¬ë§Œ
                if token.tag in ['NNP', 'NNG'] and len(token.form) >= 2:
                    keywords.append(token.form)
            
            # ìµœì†Œ 1ê°œ ë³´ì¥
            if not keywords:
                keywords = [query]
            
            return keywords[:3]
            
        except Exception as e:
            logger.warning(f"Kiwi í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨: {e}, ì›ë³¸ ì¿¼ë¦¬ ì‚¬ìš©")
            return [query]
    
    async def _search_by_keywords_pg(self, keywords: List[str], limit: int) -> List[Dict[str, Any]]:
        """
        canonical_nameìœ¼ë¡œ PostgreSQL ê²€ìƒ‰
        """
        results = []
        
        for keyword in keywords:
            try:
                # canonical_nameìœ¼ë¡œ ê²€ìƒ‰
                stmt = select(MapleDictionary).filter(
                    MapleDictionary.canonical_name.ilike(f"%{keyword}%")
                ).limit(limit)
                
                result = await self.db.execute(stmt)
                rows = result.scalars().all()
                
                for row in rows:
                    results.append({
                        "score": 100,  # ì •í™• ë§¤ì¹˜
                        "match_type": "pg_canonical",
                        "data": {
                            "category": row.category,
                            "name": row.name,
                            "canonical_name": row.canonical_name,
                            "detail_data": row.detail_data
                        }
                    })
            except Exception as e:
                logger.warning(f"PG í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨ ({keyword}): {e}")
        
        return results
    
    async def _search_by_keywords_milvus(self, keywords: List[str], limit: int) -> List[Dict[str, Any]]:
        """
        canonical_nameìœ¼ë¡œ Milvus ê²€ìƒ‰
        """
        if not self.milvus_searcher:
            return []
        
        results = []
        
        for keyword in keywords:
            try:
                # entity_nameìœ¼ë¡œ í•„í„°ë§í•˜ì—¬ ê²€ìƒ‰ (top_k íŒŒë¼ë¯¸í„° ì‚¬ìš©)
                milvus_results = await self.milvus_searcher.search(
                    query=keyword,
                    top_k=limit
                )
                
                for result in milvus_results:
                    results.append({
                        "score": result.get("score", 0) * 100,
                        "match_type": "milvus_canonical",
                        "sources": ["Milvus"],
                        "data": result
                    })
            except Exception as e:
                logger.warning(f"Milvus í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨ ({keyword}): {e}")
        
        return results
    
    async def _search_by_keywords_neo4j(self, keywords: List[str], limit: int) -> List[Dict[str, Any]]:
        """
        canonical_nameìœ¼ë¡œ Neo4j ê´€ê³„ ê²€ìƒ‰
        """
        if not self.neo4j_searcher:
            return []
        
        results = []
        
        for keyword in keywords:
            try:
                # NPC ìœ„ì¹˜ (ë©”ì„œë“œëª… ë‹¨ìˆ˜í˜•)
                npc_results = await self.neo4j_searcher.find_npc_location(keyword)
                for npc_loc in npc_results:
                    results.append({
                        "score": 90,
                        "match_type": "neo4j_npc_location",
                        "sources": ["Neo4j"],
                        "data": {
                            "npc": npc_loc.get("npc_name", ""),
                            "map": npc_loc.get("map_name", ""),
                            "relationship": f"{npc_loc.get('npc_name', '')} â†’ {npc_loc.get('map_name', '')}"
                        }
                    })
                
                # ëª¬ìŠ¤í„° ìœ„ì¹˜
                monster_results = await self.neo4j_searcher.find_monster_locations(keyword)
                for monster_loc in monster_results:
                    results.append({
                        "score": 90,
                        "match_type": "neo4j_monster_location",
                        "sources": ["Neo4j"],
                        "data": {
                            "monster": monster_loc.get("monster_name", ""),
                            "map": monster_loc.get("map_name", ""),
                            "relationship": f"{monster_loc.get('monster_name', '')} â†’ {monster_loc.get('map_name', '')}"
                        }
                    })
                
                # ì•„ì´í…œ ë“œë¡­/íŒë§¤
                item_droppers = await self.neo4j_searcher.find_item_droppers(keyword)
                for dropper in item_droppers:
                    results.append({
                        "score": 90,
                        "match_type": "neo4j_item_drop",
                        "sources": ["Neo4j"],
                        "data": {
                            "item": dropper.get("item_name", ""),
                            "monster": dropper.get("monster_name", ""),
                            "relationship": f"{dropper.get('item_name', '')} â† {dropper.get('monster_name', '')}"
                        }
                    })
                
                item_sellers = await self.neo4j_searcher.find_item_sellers(keyword)
                for seller in item_sellers:
                    results.append({
                        "score": 90,
                        "match_type": "neo4j_item_sell",
                        "sources": ["Neo4j"],
                        "data": {
                            "item": seller.get("item_name", ""),
                            "npc": seller.get("npc_name", ""),
                            "relationship": f"{seller.get('item_name', '')} â† {seller.get('npc_name', '')}"
                        }
                    })
                
            except Exception as e:
                logger.warning(f"Neo4j í‚¤ì›Œë“œ ê²€ìƒ‰ ì‹¤íŒ¨ ({keyword}): {e}")
        
        return results[:limit]
    
    def _apply_rrf_weighted(
        self,
        results_by_source: Dict[str, List[Dict[str, Any]]],
        weights: Dict[str, float] = None,
        k: int = 60
    ) -> List[Dict[str, Any]]:
        """
        ê°€ì¤‘ì¹˜ ê¸°ë°˜ RRF (Weighted Reciprocal Rank Fusion)
        
        Args:
            results_by_source: {"PostgreSQL": [...], "Milvus": [...], "Neo4j": [...]}
            weights: ê° ì†ŒìŠ¤ë³„ ê°€ì¤‘ì¹˜ (ê¸°ë³¸ê°’: {"PostgreSQL": 1.0, "Neo4j": 0.8, "Milvus": 0.3})
            k: RRF ìƒìˆ˜
        """
        if weights is None:
            weights = {"PostgreSQL": 1.0, "Neo4j": 0.8, "Milvus": 0.3}
        
        rrf_scores: Dict[str, float] = {}
        result_map: Dict[str, Dict[str, Any]] = {}
        
        for source, results in results_by_source.items():
            source_weight = weights.get(source, 1.0)
            
            for rank, result in enumerate(results, start=1):
                # canonical_name ìš°ì„ , ì—†ìœ¼ë©´ name
                result_data = result.get("data", {})
                canonical_name = result_data.get("canonical_name") or result_data.get("name", "")
                
                if not canonical_name:
                    continue
                
                # RRF ì ìˆ˜ ê³„ì‚° (ê°€ì¤‘ì¹˜ ì ìš©)
                rrf_score = source_weight / (k + rank)
                
                if canonical_name in rrf_scores:
                    rrf_scores[canonical_name] += rrf_score
                    # sources ë³‘í•©
                    if "sources" not in result_map[canonical_name]:
                        result_map[canonical_name]["sources"] = []
                    if source not in result_map[canonical_name]["sources"]:
                        result_map[canonical_name]["sources"].append(source)
                else:
                    rrf_scores[canonical_name] = rrf_score
                    result_map[canonical_name] = result.copy()
                    result_map[canonical_name]["sources"] = result.get("sources", [source])
        
        # RRF ì ìˆ˜ë¡œ ì •ë ¬
        sorted_names = sorted(rrf_scores.items(), key=lambda x: x[1], reverse=True)
        
        final_results = []
        for canonical_name, rrf_score in sorted_names:
            result = result_map[canonical_name]
            result["rrf_score"] = rrf_score
            result["score"] = rrf_score * 100  # ì ìˆ˜ ì •ê·œí™”
            final_results.append(result)
        
        return final_results


# í¸ì˜ í•¨ìˆ˜
async def hybrid_search(
    db: AsyncSession,
    query: str,
    category: Optional[str] = None,
    limit: int = 10,
    use_milvus: bool = True
) -> List[Dict[str, Any]]:
    """
    ê°„ë‹¨í•œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ í•¨ìˆ˜ (async)
    
    Usage:
        results = await hybrid_search(db, "ì•„ì´ìŠ¤ì§„ ì–´ë””ì„œ ì‚¬ë‚˜ìš”?")
    """
    searcher = HybridSearcher(db, use_milvus=use_milvus)
    return await searcher.search(query, category=category, limit=limit)
