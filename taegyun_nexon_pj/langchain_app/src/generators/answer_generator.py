"""
Answer Generator - ê²€ìƒ‰ ê²°ê³¼ë¥¼ ìì—°ì–´ ë‹µë³€ìœ¼ë¡œ ìƒì„±
"""
from typing import List, Dict, Any
from langchain_core.messages import HumanMessage, SystemMessage
from src.models.llm import create_llm, switch_to_groq
from .schema_guide import SCHEMA_GUIDE
import logging

logger = logging.getLogger(__name__)


class AnswerGenerator:
    """
    ê²€ìƒ‰ ê²°ê³¼ â†’ ìì—°ì–´ ë‹µë³€ ìƒì„±
    
    ì—­í• :
    1. ê²€ìƒ‰ ê²°ê³¼ Context ì •ë¦¬
    2. LLM Prompt ìƒì„±
    3. ìì—°ì–´ ë‹µë³€ ìƒì„±
    """
    
    SYSTEM_PROMPT = f"""ë‹¹ì‹ ì€ ë©”ì´í”ŒìŠ¤í† ë¦¬ ì „ë¬¸ ê°€ì´ë“œì…ë‹ˆë‹¤.

[ì—­í• ]
- ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ì •í™•í•˜ê²Œ ë‹µë³€í•©ë‹ˆë‹¤.
- ê²€ìƒ‰ëœ ì •ë³´ë§Œ ì‚¬ìš©í•˜ë©°, ì—†ëŠ” ì •ë³´ëŠ” ì§€ì–´ë‚´ì§€ ì•ŠìŠµë‹ˆë‹¤.
- **ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œë§Œ ë‹µë³€í•©ë‹ˆë‹¤. ì¼ë³¸ì–´, ì˜ì–´ ë“± ë‹¤ë¥¸ ì–¸ì–´ ì‚¬ìš© ê¸ˆì§€.**

{SCHEMA_GUIDE}

[ë‹µë³€ ê·œì¹™]
1. **ê²€ìƒ‰ ê²°ê³¼ì— ìˆëŠ” ì •ë³´ëŠ” ì¶©ë¶„íˆ ì œê³µ**
   - MAP(ìœ„ì¹˜) ì§ˆë¬¸: ì¥ì†Œëª… + ì§€ì—­ + ê°€ëŠ” ë°©ë²•(ìˆìœ¼ë©´)
   - NPC ì§ˆë¬¸: ì´ë¦„ + ìœ„ì¹˜ + ì—­í• (ìˆìœ¼ë©´)
   - ITEM ì§ˆë¬¸: íšë“ ë°©ë²• + í™•ë¥ (ìˆìœ¼ë©´)
   - MONSTER ì§ˆë¬¸: ì´ë¦„ + íŠ¹ì§•(ìˆìœ¼ë©´)
   
2. **ì—†ëŠ” ì •ë³´ë§Œ ì–¸ê¸‰í•˜ì§€ ë§ê¸°**
   - ê²€ìƒ‰ ê²°ê³¼ì— ì—†ëŠ” ì •ë³´ëŠ” ì™„ì „íˆ ë¬´ì‹œ
   - "í™•ì¸ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤", "ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤" ê°™ì€ ë¶€ì •ì  í‘œí˜„ ê¸ˆì§€
   
3. **ì •í™•ì„±**
   - NPC ìœ„ì¹˜ëŠ” "ìœ„ì¹˜:" í•„ë“œ ê°’ ê·¸ëŒ€ë¡œ ì‚¬ìš©
   - ë“œë í™•ë¥ ì€ ë°±ë¶„ìœ¨ë¡œ í‘œì‹œ
   - ì¶”ì¸¡í•˜ê±°ë‚˜ ìœ ì¶”í•˜ì§€ ë§ê¸°

[ë‹µë³€ ìŠ¤íƒ€ì¼]
- ìì—°ìŠ¤ëŸ½ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ (2-3ë¬¸ì¥)
- í•µì‹¬ ì •ë³´ ìš°ì„ , ë³´ì¡° ì •ë³´ ì¶”ê°€
- ì¹œì ˆí•˜ì§€ë§Œ ê°„ê²°í•˜ê²Œ

[ê¸ˆì§€ ì‚¬í•­]
- ì—†ëŠ” ì •ë³´ë¥¼ "ì—†ë‹¤"ê³  ì–¸ê¸‰í•˜ì§€ ë§ ê²ƒ
- ì§ˆë¬¸ê³¼ ì „í˜€ ê´€ë ¨ ì—†ëŠ” ì •ë³´ ì¶”ê°€í•˜ì§€ ë§ ê²ƒ"""

    def __init__(
        self,
        llm=None,
        verbose: bool = False,
    ):
        self.llm = llm if llm else create_llm(temperature=0.3)
        self.verbose = verbose

    def _switch_to_groq(self):
        """Runtimeì— Ollama ì‹¤íŒ¨ ì‹œ Groqìœ¼ë¡œ ì „í™˜"""
        result = switch_to_groq(temperature=0.3)
        if result:
            self.llm = result
    
    async def generate(
        self,
        query: str,
        search_results: List[Dict[str, Any]],
        max_context_items: int = 5
    ) -> Dict[str, Any]:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¡œ ë‹µë³€ ìƒì„± (async)
        
        Args:
            query: ì‚¬ìš©ì ì§ˆë¬¸
            search_results: Hybrid Searcher ê²°ê³¼
            max_context_items: Contextì— í¬í•¨í•  ìµœëŒ€ í•­ëª© ìˆ˜
            
        Returns:
            {
                "answer": str,
                "sources": List[str],
                "confidence": float
            }
        """
        if self.verbose:
            print(f"\nğŸ’¬ Answer Generator: '{query}'")
        
        # 1. Context êµ¬ì¶•
        context = self._build_context(search_results, max_context_items)
        
        if not context:
            return {
                "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "sources": [],
                "confidence": 0.0
            }
        
        # 2. Prompt ìƒì„±
        prompt = self._create_prompt(query, context)
        
        if self.verbose:
            print(f"   ğŸ“ Context: {len(context)}ê°œ í•­ëª©")
        
        # 3. LLM ë‹µë³€ ìƒì„± (async)
        try:
            messages = [
                SystemMessage(content=self.SYSTEM_PROMPT),
                HumanMessage(content=prompt)
            ]
            
            # ainvokeë¡œ ë¹„ë™ê¸° í˜¸ì¶œ
            response = await self.llm.ainvoke(messages)
            answer = response.content.strip()
            
            # 4. Source ì •ë¦¬
            sources = self._extract_sources(search_results[:max_context_items])
            
            # 5. ì‹ ë¢°ë„ ê³„ì‚° (í‰ê·  ì ìˆ˜)
            confidence = self._calculate_confidence(search_results[:max_context_items])

            if confidence < 60.0:
                return {
                    "answer": "ì£„ì†¡í•©ë‹ˆë‹¤. ì •í™•í•œ ë‹µë³€ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.(ì •í™•ë„ 60% ì´í•˜) ë°ì´í„° ì¶”ê°€ ì „ê¹Œì§€ ê¸°ëŒ€í•´ ì£¼ì„¸ìš”!",
                    "sources": sources,
                    "confidence": confidence
                }
            
            if self.verbose:
                print(f"   âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ (ì‹ ë¢°ë„: {confidence:.1f}%)")
            
            return {
                "answer": answer,
                "sources": sources,
                "confidence": confidence
            }
            
        except Exception as e:
            logger.error(f"ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            # Ollama Runtime ì—ëŸ¬ ì‹œ Groqìœ¼ë¡œ ì „í™˜ í›„ ì¬ì‹œë„
            if "not found" in str(e) or "404" in str(e) or "Connection" in str(e):
                self._switch_to_groq()
                try:
                    messages = [
                        SystemMessage(content=self.SYSTEM_PROMPT),
                        HumanMessage(content=prompt)
                    ]
                    response = await self.llm.ainvoke(messages)
                    answer = response.content.strip()
                    sources = self._extract_sources(search_results[:max_context_items])
                    confidence = self._calculate_confidence(search_results[:max_context_items])
                    
                    return {
                        "answer": answer,
                        "sources": sources,
                        "confidence": confidence
                    }
                except Exception as retry_error:
                    logger.error(f"Groq ì¬ì‹œë„ë„ ì‹¤íŒ¨: {retry_error}")
            
            return {
                "answer": f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "sources": [],
                "confidence": 0.0
            }
    
    def _build_context(
        self,
        search_results: List[Dict[str, Any]],
        max_items: int
    ) -> List[Dict[str, Any]]:
        """
        ê²€ìƒ‰ ê²°ê³¼ë¥¼ Contextë¡œ ì •ë¦¬
        
        ì •ë¦¬ ì „ëµ:
        1. ìƒìœ„ Nê°œë§Œ ì„ íƒ
        2. ì¤‘ë³µ ì œê±°
        3. í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ
        """
        context = []
        seen_ids = set()
        
        for result in search_results[:max_items]:
            data = result.get("data", {})
            entity_id = data.get("id")
            
            # ì¤‘ë³µ ì œê±°
            if entity_id and entity_id in seen_ids:
                continue
            
            if entity_id:
                seen_ids.add(entity_id)
            
            # Context í•­ëª© ìƒì„±
            category = data.get("category", "Unknown")
            detail_data = data.get("detail_data", {})
            
            context_item = {
                "name": data.get("canonical_name", "Unknown"),
                "category": category,
                "description": data.get("description", ""),
                "score": result.get("score", 0),
                "match_type": result.get("match_type", "unknown"),
                "sources": result.get("sources", [])
            }
            
            # ì¹´í…Œê³ ë¦¬ë³„ ìƒì„¸ ì •ë³´ ì¶”ê°€
            if category == "MAP" and detail_data:
                context_item["region"] = detail_data.get("region")
                context_item["bgm"] = detail_data.get("bgm", [])
                context_item["adjacent_maps"] = detail_data.get("adjacent_maps", [])
                context_item["special_portals"] = detail_data.get("special_portals", [])
                context_item["resident_npcs"] = detail_data.get("resident_npcs", [])
                context_item["resident_monsters"] = detail_data.get("resident_monsters", [])
            elif category == "NPC" and detail_data:
                context_item["location"] = detail_data.get("location")
                context_item["region"] = detail_data.get("region")
                context_item["services"] = detail_data.get("services", [])
            elif category == "MONSTER" and detail_data:
                context_item["level"] = detail_data.get("level")
                context_item["hp"] = detail_data.get("hp")
                context_item["mp"] = detail_data.get("mp")
                context_item["exp"] = detail_data.get("exp")
                context_item["region"] = detail_data.get("region")
                context_item["spawn_maps"] = detail_data.get("spawn_maps", [])
                context_item["drops"] = detail_data.get("drops", [])
            elif category == "ITEM" and detail_data:
                context_item["obtainable_from"] = detail_data.get("obtainable_from", [])
                context_item["dropped_by"] = detail_data.get("dropped_by", [])
            
            # ê´€ê³„ ì •ë³´ ì¶”ê°€ (Neo4j ê²°ê³¼)
            if "relation_info" in data:
                context_item["relation"] = data["relation_info"]
            
            context.append(context_item)
        
        return context
    
    def _create_prompt(self, query: str, context: List[Dict[str, Any]]) -> str:
        """
        LLM Prompt ìƒì„±
        """
        # Contextë¥¼ ì½ê¸° ì‰½ê²Œ í¬ë§·íŒ…
        context_parts = []
        for idx, item in enumerate(context):
            name = item['name']
            category = item['category']
            score = item['score']
            description = item['description'][:200] if item['description'] else ""
            
            part = f"[{idx+1}] {name} ({category}) - {score:.0f}ì \n"
            if description:
                part += f"ì„¤ëª…: {description}\n"
            
            # ì¹´í…Œê³ ë¦¬ë³„ ì¶”ê°€ ì •ë³´
            if category == "MAP":
                if item.get('region'):
                    part += f"ì§€ì—­: {item['region']}\n"
                if item.get('adjacent_maps'):
                    adjacent_str = ", ".join([m.get('target_map', '') for m in item['adjacent_maps'][:3] if m.get('target_map')])
                    if adjacent_str:
                        part += f"ì—°ê²°ëœ ë§µ: {adjacent_str}\n"
                if item.get('resident_npcs'):
                    # NPC ëª©ë¡ ì „ì²´ í‘œì‹œ (ìµœëŒ€ 10ê°œ)
                    npc_list = ', '.join(item['resident_npcs'][:10])
                    npc_count = len(item['resident_npcs'])
                    if npc_count > 10:
                        part += f"ê±°ì£¼ NPC ({npc_count}ê°œ ì¤‘ 10ê°œ): {npc_list}\n"
                    else:
                        part += f"ê±°ì£¼ NPC: {npc_list}\n"
            elif category == "NPC":
                if item.get('location'):
                    part += f"ìœ„ì¹˜: {item['location']}\n"
                if item.get('region'):
                    part += f"ì§€ì—­: {item['region']}\n"
            elif category == "MONSTER":
                if item.get('level'):
                    part += f"ë ˆë²¨: {item['level']}\n"
                if item.get('spawn_maps'):
                    part += f"ì¶œí˜„ ìœ„ì¹˜: {', '.join(item['spawn_maps'][:3])}\n"
                if item.get('drops'):
                    # ë“œë ì•„ì´í…œ ì •ë³´ (ì•„ì´í…œëª… + í™•ë¥ )
                    drops_list = []
                    for drop in item['drops'][:5]:  # ìµœëŒ€ 5ê°œ
                        item_name = drop.get('item_name', '')
                        drop_rate = drop.get('drop_rate', 0)
                        # í™•ë¥ ì„ ë°±ë¶„ìœ¨ë¡œ ë³€í™˜ (0.001 â†’ 0.1%)
                        drop_rate_percent = drop_rate * 100
                        if item_name:
                            drops_list.append(f"{item_name} ({drop_rate_percent:.2f}%)")
                    if drops_list:
                        part += f"ë“œë ì•„ì´í…œ: {', '.join(drops_list)}\n"
            elif category == "ITEM":
                if item.get('obtainable_from'):
                    part += f"êµ¬ë§¤ì²˜: {', '.join(item['obtainable_from'][:3])}\n"
                if item.get('dropped_by'):
                    part += f"ë“œë ëª¬ìŠ¤í„°: {', '.join(item['dropped_by'][:3])}\n"
            
            # Neo4j ê´€ê³„ ì •ë³´
            if 'relation' in item:
                part += f"ê´€ê³„: {item['relation']}\n"
            
            context_parts.append(part.strip())
        
        context_text = "\n\n".join(context_parts)
        
        prompt = f"""[ê²€ìƒ‰ ê²°ê³¼]

{context_text}

[ì‚¬ìš©ì ì§ˆë¬¸]
{query}

[ë‹µë³€ ì§€ì¹¨]
ìœ„ ê²€ìƒ‰ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ì ì§ˆë¬¸ì— ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.

**ë‹µë³€ ì›ì¹™:**
1. **ìˆëŠ” ì •ë³´ëŠ” ì¶©ë¶„íˆ ì œê³µ**: ìœ„ì¹˜, ì´ë¦„, ë ˆë²¨, ë“œëë¥  ë“± ê´€ë ¨ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”
2. **ì—†ëŠ” ì •ë³´ëŠ” ë¬´ì‹œ**: ê²€ìƒ‰ ê²°ê³¼ì— ì—†ìœ¼ë©´ ì•„ì˜ˆ ì–¸ê¸‰í•˜ì§€ ë§ˆì„¸ìš”
3. **ì •í™•í•˜ê²Œ**: ê²€ìƒ‰ ê²°ê³¼ì˜ í•„ë“œ ê°’ì„ ì •í™•íˆ ì½ì–´ì„œ ì‚¬ìš©í•˜ì„¸ìš”
4. **ìì—°ìŠ¤ëŸ½ê²Œ**: 2-3ë¬¸ì¥ìœ¼ë¡œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì‘ì„±í•˜ì„¸ìš”

**ì¢‹ì€ ë‹µë³€ ì˜ˆì‹œ:**
- ì§ˆë¬¸: "ë„ì  ì „ì§ ì–´ë””?" â†’ "ì»¤ë‹ì‹œí‹° ë’·ê³¨ëª©ì˜ ë‹¤í¬ë¡œë“œë¥¼ ì°¾ì•„ê°€ë©´ ë©ë‹ˆë‹¤."
- ì§ˆë¬¸: "í˜ë¦¬ì˜¨ NPC?" â†’ "í˜ë¦¬ì˜¨ì—ëŠ” ì£¼ë¨¹í´ê³  ì¼ì–´ì„œ, ì´ì–€, ë§Œì§€, ë¦¬ë²„, ì†Œí”¼ì•„ ë“±ì´ ìˆìŠµë‹ˆë‹¤."
- ì§ˆë¬¸: "ìŠ¤í¬ì•„ ë“œë?" â†’ "ìŠ¤í¬ì•„ëŠ” ì•„ì´ìŠ¤ì§„ì„ 0.10% í™•ë¥ ë¡œ ë“œëí•©ë‹ˆë‹¤."

**ë‚˜ìœ ë‹µë³€ ì˜ˆì‹œ:**
- "ì¬ì¦ˆë°” ì§€í•˜ë¡œ ê°€ì•¼ í•©ë‹ˆë‹¤." (ë„ˆë¬´ ì§§ìŒ, NPC ì´ë¦„ì´ë‚˜ ì¶”ê°€ ì •ë³´ ì—†ìŒ)
- "í˜ë¦¬ì˜¨ì— ìˆìŠµë‹ˆë‹¤. ì„œë¹„ìŠ¤ëŠ” í™•ì¸ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤." (ì—†ëŠ” ì •ë³´ë¥¼ ì–¸ê¸‰)"""
        
        return prompt
    
    def _extract_sources(self, search_results: List[Dict[str, Any]]) -> List[str]:
        """
        ê²€ìƒ‰ ê²°ê³¼ì—ì„œ ì¶œì²˜ ì¶”ì¶œ
        """
        sources = []
        seen = set()
        
        for result in search_results:
            result_sources = result.get("sources", [])
            for source in result_sources:
                if source not in seen:
                    sources.append(source)
                    seen.add(source)
        
        return sources
    
    def _calculate_confidence(self, search_results: List[Dict[str, Any]]) -> float:
        """
        ì‹ ë¢°ë„ ê³„ì‚° (í‰ê·  ì ìˆ˜)
        """
        if not search_results:
            return 0.0
        
        total_score = sum(r.get("score", 0) for r in search_results)
        avg_score = total_score / len(search_results)
        
        return min(avg_score, 100.0)  # ìµœëŒ€ 100%
