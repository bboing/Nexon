#!/usr/bin/env python3
"""
Search Agent í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸
"""
import sys
from pathlib import Path

# ê²½ë¡œ ì„¤ì •
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent
LANGCHAIN_APP_DIR = PROJECT_ROOT / "langchain_app"
sys.path.insert(0, str(LANGCHAIN_APP_DIR))

# .env ë¡œë“œ
from dotenv import load_dotenv
load_dotenv(PROJECT_ROOT / ".env")

# Import
from database.session import SessionLocal
from langchain_community.chat_models import ChatOllama
from config.settings import settings
from src.agents.search_agent import SearchAgent
import json


def test_agent(question: str, max_iterations: int = 5):
    """Agent í…ŒìŠ¤íŠ¸"""
    
    db = SessionLocal()
    print(db)

    try:
        # LLM ì´ˆê¸°í™”
        # Ollama ë¡œì»¬ ëª¨ë¸ ì‚¬ìš© (í•œêµ­ì–´ ì§€ì› ìš°ì„ ìˆœìœ„: gemma3 > llama3.1)
        model_name = "hf.co/bartowski/google_gemma-3-12b-it-GGUF:Q4_K_M"  # ë˜ëŠ” "llama3.1:latest"
        base_url = "http://localhost:11434"
        
        print(f"ğŸ¤– LLM ì´ˆê¸°í™”: {model_name}")
        print(f"ğŸ“¡ Base URL: {base_url}")
        
        from langchain_community.llms import Ollama
        from langchain_community.chat_models import ChatOllama as CommunityChatOllama
        
        llm = CommunityChatOllama(
            base_url=base_url,
            model=model_name,
            temperature=0.1
        )
        
        # Agent ì‹¤í–‰
        print("\n" + "="*80)
        print(f"â“ ì§ˆë¬¸: {question}")
        print("="*80 + "\n")
        
        # Hybrid Search ì‚¬ìš© (Milvus ì‹¤íŒ¨í•´ë„ PostgreSQLë¡œ ë™ì‘)
        agent = SearchAgent(
            db, 
            llm, 
            max_iterations=max_iterations, 
            verbose=True,
            use_hybrid=True  # Hybrid Search í™œì„±í™”
        )
        result = agent.run(question)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\n" + "="*80)
        print("ğŸ“Š Agent ì‹¤í–‰ ê²°ê³¼")
        print("="*80)
        print(f"\nâœ… ì„±ê³µ: {result['success']}")
        print(f"ğŸ”„ ë°˜ë³µ íšŸìˆ˜: {result['iterations']}/{max_iterations}")
        print(f"ğŸ’­ ìƒê° íšŸìˆ˜: {len(result['thoughts'])}")
        print(f"ğŸ” ê²€ìƒ‰ íšŸìˆ˜: {len(result['actions'])}")
        
        print(f"\nğŸ“ ìµœì¢… ë‹µë³€:")
        print("-" * 80)
        print(result['answer'])
        print("-" * 80)
        
        # ìƒì„¸ ì •ë³´
        if result['thoughts']:
            print(f"\nğŸ’­ Thoughts:")
            for idx, thought in enumerate(result['thoughts'], 1):
                print(f"  {idx}. {thought[:100]}...")
        
        if result['actions']:
            print(f"\nğŸ” Actions:")
            for idx, action in enumerate(result['actions'], 1):
                print(f"  {idx}. {action['action_type']}('{action['query']}', category={action.get('category')})")
                print(f"     â†’ {len(action['results']) if isinstance(action['results'], list) else 1}ê°œ ê²°ê³¼")
        
        print("\n" + "="*80)
        
        # JSON ì €ì¥
        output_file = PROJECT_ROOT / "logs" / "agent_result.json"
        output_file.parent.mkdir(exist_ok=True)
        with open(output_file, "w", encoding="utf-8") as f:
            json.dump(result, f, ensure_ascii=False, indent=2, default=str)
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥: {output_file}")
        
    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
    finally:
        db.close()


if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ğŸ“š ì‚¬ìš©ë²•:")
        print("  python test_search_agent.py <ì§ˆë¬¸> [ìµœëŒ€ë°˜ë³µíšŸìˆ˜]")
        print("\nì˜ˆì‹œ:")
        print('  python test_search_agent.py "ì•„ì´ìŠ¤ì§„ ì‚¬ë ¤ë©´ ì–´ë””ë¡œ ê°€ì•¼ í•˜ë‚˜ìš”?"')
        print('  python test_search_agent.py "ì£¼í™©ë²„ì„¯ì€ ì–´ë””ì„œ ì¡ë‚˜ìš”?" ')
        print('  python test_search_agent.py "í—¤ë„¤ì‹œìŠ¤ì—ì„œ í•  ìˆ˜ ìˆëŠ” ì¼ì€?"')
        sys.exit(1)
    
    question = sys.argv[1]
    max_iterations = int(sys.argv[2]) if len(sys.argv) > 2 else 5
    
    test_agent(question, max_iterations)
