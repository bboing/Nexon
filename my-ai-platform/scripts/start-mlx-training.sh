#!/bin/bash

set -e

# μ¤ν¬λ¦½νΈκ°€ μ–΄λ μ„μΉμ— μλ“  training/ λ””λ ‰ν† λ¦¬λ΅ μ΄λ™
cd "$(dirname "$0")/../training"

echo "π Apple MLX νμΈνλ‹ ν™κ²½ μ‹μ‘"
echo "================================"

# Mac ν™•μΈ
if [[ "$OSTYPE" != "darwin"* ]]; then
    echo "β μ΄ μ¤ν¬λ¦½νΈλ” Macμ—μ„λ§ μ‹¤ν–‰ κ°€λ¥ν•©λ‹λ‹¤"
    exit 1
fi

# Apple Silicon ν™•μΈ
ARCH=$(uname -m)
if [[ "$ARCH" != "arm64" ]]; then
    echo "β οΈ  κ²½κ³ : Apple Silicon (M1/M2/M3/M4/M5)μ΄ μ•„λ‹™λ‹λ‹¤"
    echo "   Intel Macμ—μ„λ” μ„±λ¥μ΄ λλ¦΄ μ μμµλ‹λ‹¤"
fi

echo "β… μ‹μ¤ν…: macOS ($(uname -m))"
echo ""

# κ°€μƒν™κ²½ ν™•μΈ
if [ ! -d "mlx-env" ]; then
    echo "π“¦ MLX κ°€μƒν™κ²½ μƒμ„± μ¤‘..."
    python3 -m venv mlx-env
    
    echo "π“¦ MLX ν¨ν‚¤μ§€ μ„¤μΉ μ¤‘..."
    source mlx-env/bin/activate
    pip install --upgrade pip -q
    echo "β… μ„¤μΉ μ™„λ£!"
else
    echo "β… MLX κ°€μƒν™κ²½ μ΅΄μ¬"
    source mlx-env/bin/activate
    echo "β… MLX κ°€μƒν™κ²½ ν™μ„±ν™”"
fi

if [ -f "requirements.txt" ]; then
    pip install -r requirements.txt -q
else
    pip install requirements.txt -q
fi

if [ ! -d "llama.cpp" ]; then
    echo "π“¦ llama.cpp μ„¤μΉ μ¤‘..."
    git clone https://github.com/ggerganov/llama.cpp.git
    cd llama.cpp
    make -j$(sysctl -n hw.logicalcpu)
    cd ..
    echo "β… llama.cpp μ„¤μΉ μ™„λ£!"
else 
    echo "β… llama.cpp μ΅΄μ¬"
fi


echo ""
echo "β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”"
echo "π€ MLX νμΈνλ‹ μ‹¤ν–‰_finetune_mlx.py"
echo "β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”"
echo ""

# νμΈνλ‹ μ‹¤ν–‰
python scripts/finetune_mlx.py


echo ""
echo "β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”"
echo "π€ μ–‘μν™” ν•΄μ _dequantize_mlx.py"
echo "β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”"
echo ""

python scripts/convert_to_gguf.py

echo ""
echo "β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”"
echo "π€ GGUF λ³€ν™_convert_to_gguf.py"
echo "β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”"
echo ""

python scripts/convert_to_gguf.py


echo "β… λ¨λ“  μ‘μ—… μ™„λ£!"
echo ""
echo "β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”"
echo "π€ Ollama λ¨λΈ λ“±λ΅"
echo "β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”"
echo ""

ollama create llama-game-npc -f models/Modelfile

echo "β… Ollama λ¨λΈ λ“±λ΅ μ™„λ£!"
echo ""
echo "β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”"
echo "local Ollama λ¨λΈ μ‹¤ν–‰ν•΄μ„ ν…μ¤νΈ ν•΄λ³΄μ„Έμ "
echo "β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”β”"
echo "/opt/homebrew/bin/ollamaμ— μμ–΄μ”. list ollama λ¨Όμ € μ²λ³΄κ³  maple_npc μ—†μΌλ©΄ create maple_npc -f $PATH_TO_MODERLFILE/Modelfile μ‹¤ν–‰ν•΄λ³΄μ„Έμ”."