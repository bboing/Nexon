# Docker Compose v2+ ì‚¬ìš© (version í•„ë“œ ì œê±°)
services:
  # Nginx - ë¦¬ë²„ìŠ¤ í”„ë¡ì‹œ
  nginx:
    image: nginx:latest
    container_name: ai-nginx
    ports:
      - "${NGINX_PORT:-80}:80"
      - "${NGINX_SSL_PORT:-443}:443"
    volumes:
      - ./nginx/nginx.conf:/etc/nginx/nginx.conf:ro
    depends_on:
      - n8n
      - grafana
    networks:
      - ai-network
    restart: unless-stopped

  # n8n - ì›Œí¬í”Œë¡œìš° ìë™í™”
  n8n:
    image: n8nio/n8n:${N8N_VERSION:-latest}
    container_name: ai-n8n
    environment:
      - N8N_BASIC_AUTH_ACTIVE=true
      - N8N_BASIC_AUTH_USER=${N8N_USER}
      - N8N_BASIC_AUTH_PASSWORD=${N8N_PASSWORD}
      - N8N_HOST=${N8N_HOST:-localhost}
      - N8N_PORT=5678
      - N8N_PROTOCOL=http
      - WEBHOOK_URL=${N8N_WEBHOOK_URL:-http://localhost:5678/}
    ports:
      - "${N8N_PORT:-5678}:5678"
    volumes:
      - ./n8n/data:/home/node/.n8n
    networks:
      - ai-network
    restart: unless-stopped

  # Ollama - LLM ëª¨ë¸ ì„œë²„
  ollama:
    image: ollama/ollama:${OLLAMA_VERSION:-latest}
    container_name: ai-ollama
    ports:
      - "${OLLAMA_PORT:-11434}:11434"
    volumes:
      - ./ollama/models:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
    networks:
      - ai-network
    restart: unless-stopped
    
    # GPU ì„¤ì • (í”Œë«í¼ë³„)
    # 
    # ğŸ Mac ì‚¬ìš©ì: ì•„ë˜ deploy ì„¹ì…˜ ì „ì²´ë¥¼ ì£¼ì„ ì²˜ë¦¬í•˜ê±°ë‚˜ ì‚­ì œí•˜ì„¸ìš”
    #    - Apple Silicon (M1/M2/M3): Metalì„ í†µí•´ ìë™ìœ¼ë¡œ GPU ê°€ì†
    #    - Intel Mac: CPU ëª¨ë“œë¡œ ì‹¤í–‰
    #
    # ğŸ§ Linux + NVIDIA GPU: ì•„ë˜ ì£¼ì„ì„ í•´ì œí•˜ì„¸ìš”
    # deploy:
    #   resources:
    #     reservations:
    #       devices:
    #         - driver: nvidia
    #           count: all
    #           capabilities: [gpu]

  # Prometheus - ë©”íŠ¸ë¦­ ìˆ˜ì§‘
  prometheus:
    image: prom/prometheus:${PROMETHEUS_VERSION:-latest}
    container_name: ai-prometheus
    ports:
      - "${PROMETHEUS_PORT:-9090}:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus-data:/prometheus
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--web.enable-lifecycle'
    networks:
      - ai-network
    restart: unless-stopped

  # Loki - ë¡œê·¸ ì €ì¥
  loki:
    image: grafana/loki:${LOKI_VERSION:-latest}
    container_name: ai-loki
    ports:
      - "${LOKI_PORT:-3100}:3100"
    volumes:
      - ./loki/config.yml:/etc/loki/local-config.yaml:ro
      - loki-data:/loki
    command: -config.file=/etc/loki/local-config.yaml
    networks:
      - ai-network
    restart: unless-stopped

  # Promtail - ë¡œê·¸ ìˆ˜ì§‘
  promtail:
    image: grafana/promtail:${PROMTAIL_VERSION:-latest}
    container_name: ai-promtail
    volumes:
      - ./promtail/config.yml:/etc/promtail/config.yml:ro
      - /var/log:/var/log:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
    command: -config.file=/etc/promtail/config.yml
    depends_on:
      - loki
    networks:
      - ai-network
    restart: unless-stopped

  # Grafana - ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ
  grafana:
    image: grafana/grafana:${GRAFANA_VERSION:-latest}
    container_name: ai-grafana
    ports:
      - "${GRAFANA_PORT:-3000}:3000"
    environment:
      - GF_SECURITY_ADMIN_USER=${GRAFANA_USER}
      - GF_SECURITY_ADMIN_PASSWORD=${GRAFANA_PASSWORD}
      - GF_INSTALL_PLUGINS=grafana-clock-panel
    volumes:
      - grafana-data:/var/lib/grafana
    depends_on:
      - prometheus
      - loki
    networks:
      - ai-network
    restart: unless-stopped

networks:
  ai-network:
    driver: bridge

volumes:
  prometheus-data:
  loki-data:
  grafana-data:

