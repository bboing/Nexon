# âš¡ ë¹ ë¥¸ ì‹œì‘ ê°€ì´ë“œ

## ğŸ¯ 3ë¶„ ì•ˆì— ì‹œì‘í•˜ê¸°

### 1ï¸âƒ£ .env íŒŒì¼ ìƒì„± (30ì´ˆ)

```bash
cd my-ai-platform

# ìµœì†Œ ì„¤ì • ë³µì‚¬
cp env.minimal .env

# ë¹„ë°€ë²ˆí˜¸ ìˆ˜ì •
nano .env
```

**ìˆ˜ì •í•  ë¶€ë¶„:**
```env
N8N_PASSWORD=YourStrongPassword123!
GRAFANA_PASSWORD=YourStrongPassword456!
```

ì €ì¥: `Ctrl+X` â†’ `Y` â†’ `Enter`

### 2ï¸âƒ£ ì‹œì‘í•˜ê¸° (1ë¶„)

```bash
./scripts/start-all.sh
```

ê¸°ë‹¤ë¦¬ë©´ ìë™ìœ¼ë¡œ ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œì‘! â˜•

### 3ï¸âƒ£ ì ‘ì†í•˜ê¸° (30ì´ˆ)

ë¸Œë¼ìš°ì €ì—ì„œ ì—´ê¸°:

- **n8n**: http://localhost:5678
- **Grafana**: http://localhost:3000
- **Ollama**: http://localhost:11434

ë¡œê·¸ì¸:
- ID: `admin`
- ë¹„ë°€ë²ˆí˜¸: `.env`ì—ì„œ ì„¤ì •í•œ ê²ƒ

### 4ï¸âƒ£ Ollama ëª¨ë¸ ë‹¤ìš´ë¡œë“œ (1ë¶„)

```bash
./scripts/ollama-pull.sh llama2
```

### 5ï¸âƒ£ í…ŒìŠ¤íŠ¸ (30ì´ˆ)

```bash
docker exec -it ai-ollama ollama run llama2 "ì•ˆë…•í•˜ì„¸ìš”"
```

## ğŸ Mac ì‚¬ìš©ì

**ì•„ë¬´ ì¶”ê°€ ì„¤ì • ì—†ì´ ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”!**

```bash
cp env.minimal .env
nano .env  # ë¹„ë°€ë²ˆí˜¸ë§Œ ìˆ˜ì •
./scripts/start-all.sh
```

Apple Silicon (M1/M2/M3)ì€ ìë™ìœ¼ë¡œ GPU ê°€ì†ë©ë‹ˆë‹¤! ğŸš€

## ğŸ§ Linux + NVIDIA GPU

**GPU ê°€ì† í™œì„±í™”:**

```bash
# 1. NVIDIA Container Toolkit ì„¤ì¹˜ (ì²˜ìŒ 1ë²ˆë§Œ)
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list
sudo apt-get update && sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker

# 2. GPU ì„¤ì • í™œì„±í™”
cp docker-compose.gpu.yml docker-compose.override.yml

# 3. ì‹œì‘
./scripts/start-all.sh
```

## ğŸ“ ì „ì²´ ëª…ë ¹ì–´ ìš”ì•½

```bash
# ì„¤ì •
cd my-ai-platform
cp env.minimal .env
nano .env

# Mac: ë°”ë¡œ ì‹œì‘
./scripts/start-all.sh

# Linux NVIDIA: GPU í™œì„±í™” í›„ ì‹œì‘
cp docker-compose.gpu.yml docker-compose.override.yml
./scripts/start-all.sh

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
./scripts/ollama-pull.sh llama2

# í…ŒìŠ¤íŠ¸
docker exec -it ai-ollama ollama run llama2 "Hello"

# ìƒíƒœ í™•ì¸
./scripts/status.sh

# ë¡œê·¸ í™•ì¸
./scripts/logs.sh
```

## ğŸ“ ë‹¤ìŒ ë‹¨ê³„

- ğŸ“– **ì „ì²´ ê°€ì´ë“œ**: `README.md`
- ğŸ–¥ï¸ **í”Œë«í¼ë³„ ì„¤ì •**: `PLATFORM_GUIDE.md`
- ğŸ® **GPU ì„¤ì •**: `GPU_SETUP.md`
- ğŸ”§ **í™˜ê²½ ë³€ìˆ˜**: `ENV_GUIDE.md`

## ğŸ†˜ ë¬¸ì œ ë°œìƒ ì‹œ

```bash
# ì¬ì‹œì‘
./scripts/restart-all.sh

# ë¡œê·¸ í™•ì¸
./scripts/logs.sh

# ìƒíƒœ í™•ì¸
./scripts/status.sh

# ì™„ì „ ì¬ì„¤ì¹˜
./scripts/cleanup.sh
./scripts/start-all.sh
```

---

**ğŸ‰ ì™„ë£Œ! ì´ì œ AI í”Œë«í¼ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤!**
