# ğŸš€ LangChain API ì‚¬ìš© ì˜ˆì œ

## ğŸ“Œ ê¸°ë³¸ ì •ë³´

- **Base URL**: `http://localhost:8000`
- **API ë¬¸ì„œ**: `http://localhost:8000/docs`
- **í—¬ìŠ¤ ì²´í¬**: `http://localhost:8000/health`

---

## ğŸ’¬ 1. ì±„íŒ… API

### ê¸°ë³¸ ì±„íŒ…

```bash
curl -X POST http://localhost:8000/api/chat/ \
  -H "Content-Type: application/json" \
  -d '{
    "message": "LangChainì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    "model": "llama2"
  }'
```

**ì‘ë‹µ:**
```json
{
  "response": "LangChainì€ LLM ì• í”Œë¦¬ì¼€ì´ì…˜ì„...",
  "session_id": "550e8400-e29b-41d4-a716-446655440000",
  "model": "llama2"
}
```

### ì„¸ì…˜ ìœ ì§€ (ëŒ€í™” ì»¨í…ìŠ¤íŠ¸)

```bash
# ì²« ë²ˆì§¸ ë©”ì‹œì§€
curl -X POST http://localhost:8000/api/chat/ \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ë‚´ ì´ë¦„ì€ ê¹€ì² ìˆ˜ì•¼",
    "model": "llama2"
  }'

# ë‘ ë²ˆì§¸ ë©”ì‹œì§€ (ê°™ì€ ì„¸ì…˜)
curl -X POST http://localhost:8000/api/chat/ \
  -H "Content-Type: application/json" \
  -d '{
    "message": "ë‚´ ì´ë¦„ì´ ë­ë¼ê³ ?",
    "session_id": "550e8400-e29b-41d4-a716-446655440000"
  }'
```

### ëŒ€í™” ê¸°ë¡ ì‚­ì œ

```bash
curl -X DELETE http://localhost:8000/api/chat/550e8400-e29b-41d4-a716-446655440000
```

---

## ğŸ“„ 2. ë¬¸ì„œ ê´€ë¦¬ API

### ë¬¸ì„œ ì—…ë¡œë“œ

```bash
# PDF ì—…ë¡œë“œ
curl -X POST http://localhost:8000/api/documents/upload \
  -F "file=@/path/to/document.pdf"

# Markdown ì—…ë¡œë“œ
curl -X POST http://localhost:8000/api/documents/upload \
  -F "file=@README.md"

# í…ìŠ¤íŠ¸ íŒŒì¼ ì—…ë¡œë“œ
curl -X POST http://localhost:8000/api/documents/upload \
  -F "file=@notes.txt"
```

**ì‘ë‹µ:**
```json
{
  "document_id": "a1b2c3d4-e5f6-7890-abcd-ef1234567890",
  "title": "document.pdf",
  "chunk_count": 42,
  "status": "completed"
}
```

### ë¬¸ì„œ ëª©ë¡ ì¡°íšŒ

```bash
curl http://localhost:8000/api/documents/
```

### ë¬¸ì„œ ì‚­ì œ

```bash
curl -X DELETE http://localhost:8000/api/documents/a1b2c3d4-e5f6-7890-abcd-ef1234567890
```

---

## ğŸ” 3. RAG (ê²€ìƒ‰-ìƒì„±) API

### RAG ì¿¼ë¦¬

```bash
curl -X POST http://localhost:8000/api/rag/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "LangChainì˜ ì£¼ìš” ê¸°ëŠ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    "top_k": 5
  }'
```

**ì‘ë‹µ:**
```json
{
  "answer": "ë¬¸ì„œì— ë”°ë¥´ë©´ LangChainì˜ ì£¼ìš” ê¸°ëŠ¥ì€...",
  "sources": [
    {
      "content": "LangChainì€ ë‹¤ìŒ ê¸°ëŠ¥ì„ ì œê³µí•©ë‹ˆë‹¤: 1. ì²´ì¸...",
      "score": 0.95,
      "metadata": {
        "document_id": "a1b2c3d4-e5f6-7890",
        "chunk_index": 5
      }
    },
    {
      "content": "LangChainì„ ì‚¬ìš©í•˜ë©´ RAGë¥¼...",
      "score": 0.87,
      "metadata": {
        "document_id": "a1b2c3d4-e5f6-7890",
        "chunk_index": 12
      }
    }
  ],
  "search_time_ms": 42,
  "generation_time_ms": 1523,
  "total_time_ms": 1565
}
```

### RAG í†µê³„

```bash
curl http://localhost:8000/api/rag/stats
```

**ì‘ë‹µ:**
```json
{
  "collection_name": "documents",
  "total_vectors": 1234,
  "dimension": 384
}
```

---

## ğŸ¤– 4. LangGraph ì—ì´ì „íŠ¸ API

### ì—°êµ¬ ì—ì´ì „íŠ¸ ì‹¤í–‰

```bash
curl -X POST http://localhost:8000/api/agents/execute \
  -H "Content-Type: application/json" \
  -d '{
    "task": "AI ë³´ì•ˆì˜ ìµœì‹  íŠ¸ë Œë“œë¥¼ ì¡°ì‚¬í•˜ê³  ë¦¬í¬íŠ¸ ì‘ì„±",
    "agent_type": "research"
  }'
```

**ì‘ë‹µ:**
```json
{
  "result": "AI ë³´ì•ˆì˜ ìµœì‹  íŠ¸ë Œë“œëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤...",
  "steps": [
    {
      "step": "research",
      "description": "ì •ë³´ ìˆ˜ì§‘ ì™„ë£Œ",
      "results_count": 3
    },
    {
      "step": "analyze",
      "description": "ë¶„ì„ ì™„ë£Œ"
    },
    {
      "step": "write_report",
      "description": "ë¦¬í¬íŠ¸ ì‘ì„± ì™„ë£Œ"
    },
    {
      "step": "review",
      "description": "ë¦¬í¬íŠ¸ ìŠ¹ì¸"
    }
  ],
  "execution_time_ms": 5234,
  "status": "completed"
}
```

### ì‚¬ìš© ê°€ëŠ¥í•œ ì—ì´ì „íŠ¸ íƒ€ì…

```bash
curl http://localhost:8000/api/agents/types
```

**ì‘ë‹µ:**
```json
{
  "agents": [
    {
      "type": "research",
      "description": "ì •ë³´ ì¡°ì‚¬ ë° ë¶„ì„ ì—ì´ì „íŠ¸",
      "capabilities": ["web_search", "document_analysis", "summarization"]
    }
  ]
}
```

---

## ğŸ Python SDK ì‚¬ìš© ì˜ˆì œ

### ì„¤ì¹˜

```bash
pip install httpx
```

### ì±„íŒ…

```python
import httpx
import asyncio

async def chat():
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/api/chat/",
            json={
                "message": "ì•ˆë…•í•˜ì„¸ìš”!",
                "model": "llama2"
            }
        )
        print(response.json())

asyncio.run(chat())
```

### ë¬¸ì„œ ì—…ë¡œë“œ ë° RAG

```python
import httpx
import asyncio

async def rag_workflow():
    async with httpx.AsyncClient(timeout=60.0) as client:
        # 1. ë¬¸ì„œ ì—…ë¡œë“œ
        with open("document.pdf", "rb") as f:
            upload_response = await client.post(
                "http://localhost:8000/api/documents/upload",
                files={"file": f}
            )
        doc_id = upload_response.json()["document_id"]
        print(f"Document uploaded: {doc_id}")
        
        # 2. RAG ì¿¼ë¦¬
        rag_response = await client.post(
            "http://localhost:8000/api/rag/query",
            json={
                "question": "ë¬¸ì„œì˜ í•µì‹¬ ë‚´ìš©ì€?",
                "top_k": 3
            }
        )
        print(f"Answer: {rag_response.json()['answer']}")

asyncio.run(rag_workflow())
```

### ì—ì´ì „íŠ¸ ì‹¤í–‰

```python
import httpx
import asyncio

async def run_agent():
    async with httpx.AsyncClient(timeout=120.0) as client:
        response = await client.post(
            "http://localhost:8000/api/agents/execute",
            json={
                "task": "ë¨¸ì‹ ëŸ¬ë‹ ìµœì‹  íŠ¸ë Œë“œ ì¡°ì‚¬",
                "agent_type": "research"
            }
        )
        
        result = response.json()
        print(f"Result: {result['result']}")
        print(f"\nExecution steps:")
        for step in result['steps']:
            print(f"  - {step['step']}: {step['description']}")

asyncio.run(run_agent())
```

---

## ğŸ§ª ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ (WebSocket)

### JavaScript ì˜ˆì œ

```javascript
// WebSocket ì—°ê²° (í–¥í›„ êµ¬í˜„ ì˜ˆì •)
const ws = new WebSocket('ws://localhost:8000/ws/chat');

ws.onopen = () => {
  ws.send(JSON.stringify({
    message: "ìŠ¤íŠ¸ë¦¬ë°ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”",
    session_id: "my-session"
  }));
};

ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  console.log(data.token); // í† í° ë‹¨ìœ„ë¡œ ìˆ˜ì‹ 
};
```

---

## ğŸ”— n8n í†µí•© ì˜ˆì œ

### HTTP Request ë…¸ë“œ ì„¤ì •

**1. ì±„íŒ… í˜¸ì¶œ**
- Method: `POST`
- URL: `http://langchain-api:8000/api/chat/`
- Body (JSON):
```json
{
  "message": "{{ $json.user_input }}",
  "model": "llama2"
}
```

**2. RAG ì¿¼ë¦¬**
- Method: `POST`
- URL: `http://langchain-api:8000/api/rag/query`
- Body (JSON):
```json
{
  "question": "{{ $json.question }}",
  "top_k": 5
}
```

**3. Slack ì•Œë¦¼ ì›Œí¬í”Œë¡œìš°**
```
[Cron íŠ¸ë¦¬ê±° (ë§¤ì¼ 9ì‹œ)]
  â†“
[HTTP: POST /api/agents/execute]
  task: "ì–´ì œ ì—…ë¡œë“œëœ ë¬¸ì„œ ìš”ì•½"
  â†“
[Slack: ë©”ì‹œì§€ ì „ì†¡]
  ì±„ë„: #daily-reports
  ë©”ì‹œì§€: {{ $json.result }}
```

---

## âš¡ ì„±ëŠ¥ ìµœì í™” íŒ

### 1. ë³‘ë ¬ RAG ì¿¼ë¦¬

```python
import httpx
import asyncio

async def parallel_rag():
    async with httpx.AsyncClient() as client:
        tasks = [
            client.post("http://localhost:8000/api/rag/query", 
                       json={"question": q})
            for q in ["ì§ˆë¬¸1", "ì§ˆë¬¸2", "ì§ˆë¬¸3"]
        ]
        responses = await asyncio.gather(*tasks)
        return [r.json() for r in responses]
```

### 2. ìºì‹± (Redis í™œìš©)

```python
# LangChain ì²´ì¸ì— ìºì‹± ìë™ ì ìš©ë¨
# ê°™ì€ ì¿¼ë¦¬ëŠ” Redisì—ì„œ ì¦‰ì‹œ ë°˜í™˜
```

### 3. ë°°ì¹˜ ë¬¸ì„œ ì—…ë¡œë“œ

```python
async def batch_upload(file_paths):
    async with httpx.AsyncClient(timeout=300.0) as client:
        tasks = []
        for path in file_paths:
            with open(path, "rb") as f:
                tasks.append(
                    client.post(
                        "http://localhost:8000/api/documents/upload",
                        files={"file": f}
                    )
                )
        return await asyncio.gather(*tasks)
```

---

## ğŸ› ì—ëŸ¬ ì²˜ë¦¬

### ì¼ë°˜ì ì¸ ì—ëŸ¬ ì½”ë“œ

```json
// 400 Bad Request
{
  "detail": "Invalid request format"
}

// 500 Internal Server Error
{
  "detail": "Milvus connection failed"
}

// 503 Service Unavailable
{
  "detail": "Ollama service not ready"
}
```

### ì¬ì‹œë„ ë¡œì§

```python
import httpx
from tenacity import retry, stop_after_attempt, wait_fixed

@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))
async def robust_query(question: str):
    async with httpx.AsyncClient() as client:
        response = await client.post(
            "http://localhost:8000/api/rag/query",
            json={"question": question}
        )
        response.raise_for_status()
        return response.json()
```

---

## ğŸ“Š ëª¨ë‹ˆí„°ë§

### Prometheus ë©”íŠ¸ë¦­

```bash
# API í˜¸ì¶œ íšŸìˆ˜
curl http://localhost:8000/metrics | grep api_calls_total

# í‰ê·  ì‘ë‹µ ì‹œê°„
curl http://localhost:8000/metrics | grep api_latency_seconds
```

### ë¡œê·¸ í™•ì¸

```bash
# LangChain API ë¡œê·¸
docker compose -f docker-compose.langchain.yml logs -f langchain-api

# íŠ¹ì • ì‹œê°„ëŒ€ ë¡œê·¸ (Grafana Loki)
# Grafana â†’ Explore â†’ Loki â†’ {container="ai-langchain-api"}
```

---

**ë” ë§ì€ ì˜ˆì œëŠ” `http://localhost:8000/docs`ì—ì„œ í™•ì¸í•˜ì„¸ìš”! ğŸ‰**
