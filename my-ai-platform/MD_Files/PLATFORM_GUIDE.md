# ğŸ–¥ï¸ í”Œë«í¼ë³„ ì„¤ì • ê°€ì´ë“œ

## ë¹ ë¥¸ ë¹„êµí‘œ

| í”Œë«í¼ | GPU ì§€ì› | ì¶”ê°€ ì„¤ì • | ê¶Œì¥ ëª¨ë¸ í¬ê¸° |
|--------|---------|----------|---------------|
| **Mac M1/M2/M3** | âœ… Metal (ìë™) | ë¶ˆí•„ìš” | ~13B |
| **Mac Intel** | âŒ CPUë§Œ | ë¶ˆí•„ìš” | ~7B |
| **Linux NVIDIA** | âœ… CUDA | í•„ìš” | ~70B |
| **Linux AMD** | âš ï¸ ROCm | ë³µì¡ | ~13B |
| **Windows WSL2** | âœ… CUDA | í•„ìš” | ~70B |
| **Windows Native** | âŒ ë¹„ì¶”ì²œ | - | - |

---

## ğŸ Mac (macOS)

### âœ… ì„¤ì • ì™„ë£Œ! ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”

```bash
cd my-ai-platform

# 1. .env íŒŒì¼ ìƒì„±
cp env.minimal .env
nano .env  # ë¹„ë°€ë²ˆí˜¸ ìˆ˜ì •

# 2. ì‹œì‘
./scripts/start-all.sh

# 3. ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
./scripts/ollama-pull.sh llama2
```

### ğŸ¯ Mac íŠ¹ì§•

**Apple Silicon (M1/M2/M3/M4):**
- âœ… Metalì„ í†µí•œ ìë™ GPU ê°€ì†
- âœ… í†µí•© ë©”ëª¨ë¦¬ í™œìš© (8GB~96GB)
- âœ… ì „ë ¥ íš¨ìœ¨ì 
- ğŸš€ 7B ëª¨ë¸ì€ ë§¤ìš° ë¹ ë¦„
- âš ï¸ 13B ì´ìƒì€ ë©”ëª¨ë¦¬ì— ë”°ë¼ ë‹¤ë¦„

**Intel Mac:**
- âš ï¸ CPU ëª¨ë“œë§Œ
- âš ï¸ 7B ì´í•˜ ëª¨ë¸ ê¶Œì¥
- âš ï¸ ëŠë¦° ì‘ë‹µ ì†ë„

### ğŸ“ Macì—ì„œ ì£¼ì˜ì‚¬í•­

```bash
# âŒ ì´ëŸ° ì—ëŸ¬ê°€ ë‚˜ë©´
Error: nvidia driver not found

# âœ… ì •ìƒì…ë‹ˆë‹¤! ë¬´ì‹œí•˜ì„¸ìš”
# docker-compose.ymlì—ì„œ GPU ì„¤ì •ì´ ì£¼ì„ ì²˜ë¦¬ë˜ì–´ì•¼ í•¨
```

---

## ğŸ§ Linux

### NVIDIA GPU ìˆëŠ” ê²½ìš°

**1ï¸âƒ£ NVIDIA Container Toolkit ì„¤ì¹˜**

```bash
# Ubuntu/Debian
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg

distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit
sudo systemctl restart docker
```

**2ï¸âƒ£ GPU í™œì„±í™”**

```bash
cd my-ai-platform

# GPU ì„¤ì • í™œì„±í™”
cp docker-compose.gpu.yml docker-compose.override.yml

# .env ì„¤ì •
cp env.minimal .env
nano .env

# ì‹œì‘
./scripts/start-all.sh
```

**3ï¸âƒ£ GPU í™•ì¸**

```bash
# GPU ì‘ë™ í™•ì¸
docker exec -it ai-ollama nvidia-smi

# ëª¨ë¸ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
./scripts/ollama-pull.sh llama2
docker exec -it ai-ollama ollama run llama2 "Hello"
```

### CPUë§Œ ìˆëŠ” ê²½ìš°

```bash
# ê¸°ë³¸ ì„¤ì • ì‚¬ìš©
./scripts/start-all.sh

# ê²½ëŸ‰ ëª¨ë¸ ì‚¬ìš©
./scripts/ollama-pull.sh gemma:2b
./scripts/ollama-pull.sh phi
```

---

## ğŸªŸ Windows

### WSL2 ì‚¬ìš© (ê¶Œì¥) âœ…

**1ï¸âƒ£ WSL2 ì„¤ì¹˜**

```powershell
# PowerShell (ê´€ë¦¬ì ê¶Œí•œ)
wsl --install -d Ubuntu
```

**2ï¸âƒ£ NVIDIA GPU ì§€ì› (GPUê°€ ìˆëŠ” ê²½ìš°)**

1. Windowsì—ì„œ NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜
   - [CUDA on WSL](https://developer.nvidia.com/cuda/wsl)ì—ì„œ ë‹¤ìš´ë¡œë“œ
   - WSL2ìš© íŠ¹ìˆ˜ ë“œë¼ì´ë²„ í•„ìš”

2. WSL2 ë‚´ë¶€ì—ì„œ Linux ê°€ì´ë“œ ë”°ë¼í•˜ê¸°
   ```bash
   wsl -d Ubuntu
   cd /mnt/c/Users/YourName/my-ai-platform
   # Linux NVIDIA ê°€ì´ë“œ ì°¸ê³ 
   ```

**3ï¸âƒ£ Docker Desktop ì‚¬ìš©**

- Docker Desktop for Windows ì„¤ì¹˜
- WSL2 integration í™œì„±í™”
- Settings â†’ Resources â†’ WSL Integration

### Windows Native (ë¹„ì¶”ì²œ) âš ï¸

- Docker Desktopì˜ Windows ContainerëŠ” ì œí•œì 
- WSL2 ì‚¬ìš©ì„ ê°•ë ¥íˆ ê¶Œì¥

---

## ğŸ”§ í”Œë«í¼ë³„ ìµœì  ì„¤ì •

### Mac M1/M2/M3 ìµœì í™”

```bash
# .env ì„¤ì •
N8N_USER=admin
N8N_PASSWORD=YourPassword123!
GRAFANA_USER=admin
GRAFANA_PASSWORD=YourPassword456!

# ì¶”ì²œ ëª¨ë¸ (ë©”ëª¨ë¦¬ë³„)
# 8GB RAM
./scripts/ollama-pull.sh gemma:2b
./scripts/ollama-pull.sh phi

# 16GB RAM
./scripts/ollama-pull.sh llama2
./scripts/ollama-pull.sh mistral
./scripts/ollama-pull.sh codellama

# 32GB+ RAM
./scripts/ollama-pull.sh llama2:13b
./scripts/ollama-pull.sh mixtral
```

### Linux NVIDIA ìµœì í™”

```bash
# GPU ë©”ëª¨ë¦¬ë³„ ê¶Œì¥ ëª¨ë¸
# 8GB VRAM
./scripts/ollama-pull.sh llama2
./scripts/ollama-pull.sh mistral

# 16GB VRAM
./scripts/ollama-pull.sh llama2:13b
./scripts/ollama-pull.sh mixtral

# 24GB+ VRAM (3090, 4090, A100)
./scripts/ollama-pull.sh llama2:70b
./scripts/ollama-pull.sh mixtral:8x7b

# ë©”ëª¨ë¦¬ ë¶€ì¡± ì‹œ ì–‘ìí™” ëª¨ë¸
./scripts/ollama-pull.sh llama2:7b-q4_0  # 4-bit
```

### CPU ì „ìš© ìµœì í™”

```bash
# ê²½ëŸ‰ ëª¨ë¸ë§Œ ì‚¬ìš©
./scripts/ollama-pull.sh gemma:2b
./scripts/ollama-pull.sh phi:2.7b
./scripts/ollama-pull.sh tinyllama

# ì“°ë ˆë“œ ìˆ˜ ì œí•œ (env íŒŒì¼ì— ì¶”ê°€)
OLLAMA_NUM_PARALLEL=1
OLLAMA_MAX_LOADED_MODELS=1
```

---

## ğŸ§ª ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

### ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸

```bash
#!/bin/bash
# benchmark.sh

echo "ğŸ§ª í”Œë«í¼ ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"
echo ""

# ì‹œìŠ¤í…œ ì •ë³´
echo "ğŸ“Š ì‹œìŠ¤í…œ ì •ë³´:"
uname -a

if [[ "$OSTYPE" == "darwin"* ]]; then
    sysctl -n machdep.cpu.brand_string
    sysctl hw.memsize
elif command -v nvidia-smi &> /dev/null; then
    nvidia-smi --query-gpu=name,memory.total --format=csv
fi

echo ""
echo "â±ï¸ ì‘ë‹µ ì‹œê°„ ì¸¡ì •..."

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
docker exec ai-ollama ollama pull llama2 2>/dev/null

# í…ŒìŠ¤íŠ¸
echo "Test 1: ì§§ì€ ì‘ë‹µ"
time docker exec ai-ollama ollama run llama2 "Hi" 2>/dev/null

echo ""
echo "Test 2: ì¤‘ê°„ ì‘ë‹µ"
time docker exec ai-ollama ollama run llama2 "Explain AI in one paragraph" 2>/dev/null
```

```bash
chmod +x benchmark.sh
./benchmark.sh
```

---

## ğŸ“Š ì˜ˆìƒ ì„±ëŠ¥

### ì‘ë‹µ ì†ë„ ë¹„êµ (llama2:7b ê¸°ì¤€)

| í”Œë«í¼ | ì´ˆê¸° ë¡œë”© | í† í°/ì´ˆ |
|--------|----------|---------|
| Mac M1 | ~2ì´ˆ | ~20 |
| Mac M2 Pro | ~1ì´ˆ | ~30 |
| Mac M3 Max | ~1ì´ˆ | ~50 |
| RTX 3090 | ~1ì´ˆ | ~60 |
| RTX 4090 | <1ì´ˆ | ~100 |
| CPU (i9) | ~5ì´ˆ | ~5 |

---

## ğŸ†˜ í”Œë«í¼ë³„ ë¬¸ì œ í•´ê²°

### Mac ë¬¸ì œ

```bash
# Dockerê°€ ëŠë¦° ê²½ìš°
# Docker Desktop â†’ Settings â†’ Resources
# CPU: ìµœì†Œ 4ì½”ì–´
# Memory: ìµœì†Œ 8GB
# Disk: ìµœì†Œ 20GB

# ì¬ì‹œì‘
./scripts/restart-all.sh
```

### Linux ë¬¸ì œ

```bash
# GPU ì¸ì‹ ì•ˆ ë¨
sudo nvidia-smi  # ë“œë¼ì´ë²„ í™•ì¸
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi  # Docker GPU í…ŒìŠ¤íŠ¸

# ê¶Œí•œ ë¬¸ì œ
sudo usermod -aG docker $USER
newgrp docker
```

### Windows WSL2 ë¬¸ì œ

```bash
# WSL2ì—ì„œ Docker ì•ˆ ë³´ì„
# Docker Desktop â†’ Settings â†’ Resources â†’ WSL Integration
# Ubuntu ì²´í¬ë°•ìŠ¤ í™œì„±í™”

# ì¬ì‹œì‘
wsl --shutdown
# Docker Desktop ì¬ì‹œì‘
```

---

## ğŸ’¡ í”Œë«í¼ë³„ ê¶Œì¥ ì‚¬í•­

### âœ… Mac ì‚¬ìš©ìê»˜
- ê·¸ëƒ¥ ì‹œì‘í•˜ì„¸ìš”! ì„¤ì • í•„ìš” ì—†ìŒ
- M1/M2/M3ë¼ë©´ 13B ëª¨ë¸ë„ ê°€ëŠ¥
- ë©”ëª¨ë¦¬ 16GB+ ê¶Œì¥

### âœ… Linux NVIDIA ì‚¬ìš©ìê»˜
- GPU ì„¤ì • í™œì„±í™” í•„ìˆ˜
- í° ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥
- VRAM í™•ì¸ í›„ ëª¨ë¸ ì„ íƒ

### âœ… CPUë§Œ ìˆëŠ” ì‚¬ìš©ìê»˜
- ê²½ëŸ‰ ëª¨ë¸ ì‚¬ìš© (2B-7B)
- ì¸ë‚´ì‹¬ í•„ìš” ğŸŒ
- ì—…ê·¸ë ˆì´ë“œ ê³ ë ¤

---

**ìƒì„¸ GPU ì„¤ì •:** `GPU_SETUP.md` ì°¸ê³ 

