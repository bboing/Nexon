# ğŸ® GPU ì„¤ì • ê°€ì´ë“œ

## ğŸ Mac ì‚¬ìš©ì

### Apple Silicon (M1/M2/M3/M4)

**âœ… ì¢‹ì€ ì†Œì‹: ì¶”ê°€ ì„¤ì • ë¶ˆí•„ìš”!**

- Ollamaê°€ ìë™ìœ¼ë¡œ **Metal**ì„ í†µí•´ GPU ê°€ì†
- `docker-compose.yml` ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë©´ ë¨
- NVIDIA ì„¤ì •ì€ ë¬´ì‹œë¨

```bash
# ê·¸ëƒ¥ ì‹œì‘í•˜ë©´ ë©ë‹ˆë‹¤
./scripts/start-all.sh
```

**ì„±ëŠ¥ í™•ì¸:**
```bash
# ëª¨ë¸ ì‹¤í–‰ ì†ë„ ì²´í¬
docker exec -it ai-ollama ollama run llama2 "Hello"
# ë¹ ë¥´ë©´ GPU ê°€ì† ì¤‘!
```

### Intel Mac

- CPU ëª¨ë“œë¡œ ì‹¤í–‰ë¨
- GPU ê°€ì† ì—†ìŒ (ì •ìƒ)
- ì‘ì€ ëª¨ë¸ ì‚¬ìš© ê¶Œì¥ (llama2:7b, gemma:2b)

---

## ğŸ§ Linux + NVIDIA GPU ì‚¬ìš©ì

### 1ï¸âƒ£ ì‚¬ì „ ìš”êµ¬ì‚¬í•­

```bash
# NVIDIA ë“œë¼ì´ë²„ í™•ì¸
nvidia-smi

# NVIDIA Container Toolkit ì„¤ì¹˜
distribution=$(. /etc/os-release;echo $ID$VERSION_ID)
curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg
curl -s -L https://nvidia.github.io/libnvidia-container/$distribution/libnvidia-container.list | \
    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \
    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list

sudo apt-get update
sudo apt-get install -y nvidia-container-toolkit

# Docker ì¬ì‹œì‘
sudo systemctl restart docker
```

### 2ï¸âƒ£ GPU í™œì„±í™” ë°©ë²•

**ë°©ë²• A: Override íŒŒì¼ ì‚¬ìš© (ê¶Œì¥)**

```bash
cd my-ai-platform

# override íŒŒì¼ë¡œ ë³€ê²½
cp docker-compose.gpu.yml docker-compose.override.yml

# í‰ì†Œì²˜ëŸ¼ ì‹œì‘ (ìë™ìœ¼ë¡œ GPU ì„¤ì • ì ìš©)
docker-compose up -d
# ë˜ëŠ”
./scripts/start-all.sh
```

**ë°©ë²• B: ì§ì ‘ ì§€ì •**

```bash
# ëª…ì‹œì ìœ¼ë¡œ GPU ì„¤ì • íŒŒì¼ ì‚¬ìš©
docker-compose -f docker-compose.yml -f docker-compose.gpu.yml up -d
```

**ë°©ë²• C: docker-compose.yml ì§ì ‘ ìˆ˜ì •**

```yaml
# docker-compose.ymlì—ì„œ ì£¼ì„ í•´ì œ
ollama:
  deploy:
    resources:
      reservations:
        devices:
          - driver: nvidia
            count: all
            capabilities: [gpu]
```

### 3ï¸âƒ£ GPU ì‘ë™ í™•ì¸

```bash
# GPU ì‚¬ìš© í™•ì¸
docker exec -it ai-ollama nvidia-smi

# ë˜ëŠ” Ollamaì—ì„œ í™•ì¸
docker logs ai-ollama | grep -i gpu
```

---

## ğŸªŸ Windows + WSL2 + NVIDIA GPU

### 1ï¸âƒ£ WSL2ì—ì„œ NVIDIA ì„¤ì •

```powershell
# Windowsì—ì„œ NVIDIA ë“œë¼ì´ë²„ ì„¤ì¹˜ (WSL2ìš©)
# https://developer.nvidia.com/cuda/wsl ì—ì„œ ë‹¤ìš´ë¡œë“œ

# WSL2 ë‚´ë¶€ì—ì„œ
wsl -d Ubuntu
```

### 2ï¸âƒ£ Linux ê°€ì´ë“œì™€ ë™ì¼

ìœ„ì˜ "Linux + NVIDIA GPU" ê°€ì´ë“œë¥¼ ë”°ë¼í•˜ì„¸ìš”.

---

## ğŸ“Š ì„±ëŠ¥ ë¹„êµ

| í™˜ê²½ | ëª¨ë¸ ë¡œë”© | ì‘ë‹µ ì†ë„ | ê¶Œì¥ ëª¨ë¸ í¬ê¸° |
|------|----------|----------|---------------|
| **Mac M1/M2/M3** | ë¹ ë¦„ âš¡ | ë¹ ë¦„ âš¡ | 13B ì´í•˜ |
| **Linux NVIDIA** | ë§¤ìš° ë¹ ë¦„ ğŸš€ | ë§¤ìš° ë¹ ë¦„ ğŸš€ | 70B ê°€ëŠ¥ |
| **CPUë§Œ** | ëŠë¦¼ ğŸŒ | ëŠë¦¼ ğŸŒ | 7B ì´í•˜ ê¶Œì¥ |

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

### GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸

```bash
#!/bin/bash
# gpu-test.sh

echo "ğŸ§ª GPU ì„±ëŠ¥ í…ŒìŠ¤íŠ¸"
echo ""

# ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
docker exec -it ai-ollama ollama pull llama2

# ì‘ë‹µ ì‹œê°„ ì¸¡ì •
echo "í…ŒìŠ¤íŠ¸ 1: ì§§ì€ ì‘ë‹µ"
time docker exec ai-ollama ollama run llama2 "Hi" --verbose

echo ""
echo "í…ŒìŠ¤íŠ¸ 2: ê¸´ ì‘ë‹µ"
time docker exec ai-ollama ollama run llama2 "Explain quantum physics"

echo ""
echo "âœ… GPU ê°€ì†ì´ ì •ìƒì´ë©´ ìœ„ ëª…ë ¹ì´ ë¹ ë¥´ê²Œ ì‹¤í–‰ë©ë‹ˆë‹¤"
```

---

## ğŸ”§ ë¬¸ì œ í•´ê²°

### Macì—ì„œ "nvidia driver not found" ì—ëŸ¬

```bash
# ì •ìƒì…ë‹ˆë‹¤! GPU ì„¤ì •ì´ ì£¼ì„ ì²˜ë¦¬ë˜ì—ˆëŠ”ì§€ í™•ì¸
cat docker-compose.yml | grep -A 5 "# deploy:"

# ë˜ëŠ” ì»¨í…Œì´ë„ˆ ì¬ìƒì„±
docker-compose down
docker-compose up -d
```

### Linuxì—ì„œ GPU ì¸ì‹ ì•ˆ ë¨

```bash
# 1. NVIDIA ë“œë¼ì´ë²„ í™•ì¸
nvidia-smi

# 2. Dockerê°€ GPUë¥¼ ë³¼ ìˆ˜ ìˆëŠ”ì§€ í™•ì¸
docker run --rm --gpus all nvidia/cuda:11.0-base nvidia-smi

# 3. Container Toolkit ì¬ì„¤ì¹˜
sudo apt-get install --reinstall nvidia-container-toolkit
sudo systemctl restart docker
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±

```bash
# ì‘ì€ ëª¨ë¸ ì‚¬ìš©
docker exec -it ai-ollama ollama pull gemma:2b
docker exec -it ai-ollama ollama pull llama2:7b

# í° ëª¨ë¸ ì‚­ì œ
docker exec -it ai-ollama ollama rm llama2:70b
```

---

## ğŸ’¡ ê¶Œì¥ ì„¤ì •

### ğŸ Mac ì‚¬ìš©ì
```bash
# ê¸°ë³¸ ì„¤ì • ê·¸ëŒ€ë¡œ ì‚¬ìš©
./scripts/start-all.sh

# ì¶”ì²œ ëª¨ë¸
./scripts/ollama-pull.sh llama2        # 7B
./scripts/ollama-pull.sh mistral       # 7B
./scripts/ollama-pull.sh codellama     # 7B
```

### ğŸ§ Linux NVIDIA ì‚¬ìš©ì
```bash
# GPU í™œì„±í™”
cp docker-compose.gpu.yml docker-compose.override.yml
./scripts/start-all.sh

# í° ëª¨ë¸ë„ ê°€ëŠ¥
./scripts/ollama-pull.sh llama2:13b
./scripts/ollama-pull.sh llama2:70b    # VRAM 40GB+ í•„ìš”
```

### ğŸ–¥ï¸ CPUë§Œ ìˆëŠ” ê²½ìš°
```bash
# ê²½ëŸ‰ ëª¨ë¸ë§Œ ì‚¬ìš©
./scripts/ollama-pull.sh gemma:2b
./scripts/ollama-pull.sh phi
```

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [Ollama Docker ê°€ì´ë“œ](https://github.com/ollama/ollama/blob/main/docs/docker.md)
- [NVIDIA Container Toolkit](https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html)
- [Apple Metal ì„±ëŠ¥](https://ollama.com/blog/metal-support)

---

**ğŸ’¡ TIP:** Macì´ë¼ë©´ ë³„ë„ ì„¤ì • ì—†ì´ ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”! Apple Siliconì´ ì•Œì•„ì„œ GPU ê°€ì†ì„ í•´ì¤ë‹ˆë‹¤. ğŸš€

