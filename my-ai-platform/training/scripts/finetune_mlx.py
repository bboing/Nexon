#!/usr/bin/env python3
"""
Apple MLXλ¥Ό μ΄μ©ν• LoRA νμΈνλ‹
M1/M2/M3 Mac μµμ ν™”
"""

from mlx_lm import load, generate
from mlx_lm.tuner import train
from mlx_lm.utils import load as mlx_load, save_config
import mlx.core as mx
import json
import random
from pathlib import Path

print("π Apple MLX νμΈνλ‹ μ‹μ‘!")
print(f"   MLX Device: Metal GPU")
print(f"   Memory: Unified Memory")

# ============================================================
# 1. μ„¤μ •
# ============================================================
CONFIG = {
    # λ¨λΈ μ„¤μ •
    "model": "meta-llama/Llama-3.1-8B-Instruct",
    "adapter_file": "adapters.safetensors",  # LoRA μ–΄λ‘ν„° μ €μ¥ νμΌ
    
    # ν•™μµ μ„¤μ •
    "train": True,
    "batch_size": 8,
    "iters": 600,  # ν•™μµ iteration (ν…μ¤νΈ: 100, μ‹¤μ „: 1000+)
    "val_batches": 25,
    "learning_rate": 1e-5,
    "steps_per_report": 10,
    "steps_per_eval": 100,
    "save_every": 50,
    "test": False,
    "test_batches": 100,
    
    # LoRA μ„¤μ •
    "lora_layers": 32,  # LoRAλ¥Ό μ μ©ν•  λ μ΄μ–΄ μ
    "lora_rank": 16,  # LoRA rank (8~32 κ¶μ¥)
    "lora_scale": 20.0,
    
    # λ°μ΄ν„°μ…‹
    "data": "../data",  # λ°μ΄ν„° λ””λ ‰ν† λ¦¬
    "seed": 42,
}

# ============================================================
# 2. λ°μ΄ν„°μ…‹ μ¤€λΉ„ (Alpaca ν•μ‹)
# ============================================================

data_dir = Path(__file__).parent.parent / "data"
data_dir.mkdir(exist_ok=True)
input_file = data_dir / "input_data" / "maple_npc.json" # μ›λ³Έ λ°μ΄ν„° 
train_path = data_dir / "train.jsonl"   # λ³€ν™λ ν•™μµμ© λ°μ΄ν„°

# λ°μ΄ν„° λ΅λ“
with open(input_file, "r", encoding="utf-8") as f:
    raw_data = json.load(f)

print(f"π”„ λ³€ν™ μ‹μ‘: μ΄ {len(raw_data)}κ° λ°μ΄ν„°")

converted_data = []

# 2. λ£¨ν”„ λλ©΄μ„ ν¬λ§· λ³€ν™ (ν•µμ‹¬ λ΅μ§)
for item in raw_data:
    system_content = f"λ‹Ήμ‹ μ€ '{item['City']}'μ— κ±°μ£Όν•λ” NPC '{item['NPC_Name']}'μ…λ‹λ‹¤. {item['instruction']}"
    
    entry = {
        "messages": [
            {"role": "system", "content": system_content},
            {"role": "user", "content": item['input']},
            {"role": "assistant", "content": item['output']}
        ]
    }
    converted_data.append(entry)

# 3. JSONL νμΌλ΅ μ €μ¥ (ν• μ¤„μ— json ν•λ‚μ”©)
with open(train_path, "w", encoding="utf-8") as f:
    # row_count = sum(1 for _ in f)
    for entry in converted_data:
        json.dump(entry, f, ensure_ascii=False)
        f.write("\n") # μ¤„λ°”κΏ ν•„μ



# valid.jsonl μƒμ„± (validation)
if len(converted_data) > 1:
    first_msg = converted_data[0]['messages'][0]['content']
    last_msg = converted_data[-1]['messages'][0]['content']
    
    if first_msg == last_msg:
        print("π¨ [κ²½κ³ ] μ—¬μ „ν λ¨λ“  λ°μ΄ν„°κ°€ λ‘κ°™μµλ‹λ‹¤! μ›λ³Έ(raw_data)μ΄ μ¤‘λ³µμΈμ§€ ν™•μΈν•μ„Έμ”.")
    else:
        print("β¨ [μ„±κ³µ] λ°μ΄ν„°κ°€ μ„λ΅ λ‹¤λ¦…λ‹λ‹¤. μ΄μ  λλ¤ μ¶”μ¶μ΄ μ •μƒ μ‘λ™ν•©λ‹λ‹¤.")

    valid_path = data_dir / "valid.jsonl"
    random_valid_data = random.sample(converted_data, min(10, len(converted_data)))
    print(f"random_valid_data : {random_valid_data}")

    with open(valid_path, "w", encoding="utf-8") as f:
        for item in random_valid_data:  # λλ¤
            json.dump(item, f, ensure_ascii=False)
            f.write("\n")

        
print(f"β… λ°μ΄ν„°μ…‹ μ¤€λΉ„ μ™„λ£!")
print(f"   Train: {train_path} ({len(converted_data)}κ°)")
print(f"   Valid: {valid_path} (10κ°)")

# ============================================================
# 3. λ¨λΈ λ΅λ“
# ============================================================
print(f"\nπ“¦ λ¨λΈ λ‹¤μ΄λ΅λ“ μ¤‘: {CONFIG['model']}")
print("   (μ²« μ‹¤ν–‰ μ‹ μ‹κ°„μ΄ κ±Έλ¦½λ‹λ‹¤...)")

try:
    model, tokenizer = load(CONFIG['model'])
    print("β… λ¨λΈ λ΅λ“ μ™„λ£!")
except Exception as e:
    print(f"β λ¨λΈ λ΅λ“ μ‹¤ν¨: {e}")
    print("\nπ’΅ ν•΄κ²° λ°©λ²•:")
    print("   1. μΈν„°λ„· μ—°κ²° ν™•μΈ")
    print("   2. Hugging Face ν† ν° μ„¤μ •:")
    print("      huggingface-cli login")
    exit(1)

# ============================================================
# 4. νμΈνλ‹ μ‹¤ν–‰
# ============================================================
print("\nπ€ MLX LoRA νμΈνλ‹ μ‹μ‘!")
print(f"   Iterations: {CONFIG['iters']}")
print(f"   LoRA Rank: {CONFIG['lora_rank']}")
print(f"   Learning Rate: {CONFIG['learning_rate']}")
print("")

# μ¶λ ¥ λ””λ ‰ν† λ¦¬
output_dir = Path(__file__).parent.parent / "models" / "llama-game-npc-mlx"
output_dir.mkdir(parents=True, exist_ok=True)

# mlx-lm train λ…λ Ήμ–΄ κµ¬μ„±
import subprocess
import sys

cmd = [
    sys.executable, "-m", "mlx_lm.lora",
    "--model", CONFIG['model'],
    "--train",
    "--data", str(data_dir),
    "--batch-size", str(CONFIG['batch_size']),
    "--iters", str(CONFIG['iters']),
    "--learning-rate", str(CONFIG['learning_rate']),
    "--num-layers", str(CONFIG['lora_layers']),
    "--adapter-path", str(output_dir),
]

print("π“ μ‹¤ν–‰ λ…λ Ήμ–΄:")
print(" ".join(cmd))
print("")

# ν•™μµ μ‹¤ν–‰
try:
    result = subprocess.run(cmd, check=True, cwd=output_dir)
    print("\nβ… νμΈνλ‹ μ™„λ£!")
except subprocess.CalledProcessError as e:
    print(f"\nβ νμΈνλ‹ μ‹¤ν¨: {e}")
    exit(1)

# ============================================================
# 5. μ €μ¥
# ============================================================
print(f"\nπ’Ύ λ¨λΈ μ €μ¥ μ„μΉ:")
print(f"   {output_dir}")
print(f"   β”β”€ adapters.safetensors (LoRA κ°€μ¤‘μΉ)")
print(f"   β””β”€ config.json (μ„¤μ •)")

# ============================================================
# 6. μ¶”λ΅  ν…μ¤νΈ
# ============================================================
print("\nπ® μ¶”λ΅  ν…μ¤νΈ:")

# LoRA μ–΄λ‘ν„°μ™€ ν•¨κ» λ¨λΈ λ΅λ“
try:
    model, tokenizer = load(
        CONFIG['model'],
        adapter_path=str(output_dir)
    )
    
    test_prompt = "λ„μ μΌλ΅ μ „μ§ν•κ³  μ‹¶μ–΄μ” NPC:"
    
    print(f"\nμ…λ ¥: {test_prompt}")
    print("μ¶λ ¥: ", end="")
    
    response = generate(
        model,
        tokenizer,
        prompt=test_prompt,
        max_tokens=100,
        temp=0.7,
    )
    
    print(response)
    
except Exception as e:
    print(f"β μ¶”λ΅  μ‹¤ν¨: {e}")

print("\n" + "="*60)
print("β… MLX νμΈνλ‹ μ™„λ£! π‰")
print("="*60)

print("\nπ“‹ λ‹¤μ λ‹¨κ³„:")
print("1. Ollama Modelfile μƒμ„±:")
print("   - adapters.safetensorsλ¥Ό Ollama ν•μ‹μΌλ΅ λ³€ν™")
print("")
print("2. μ¶”κ°€ ν•™μµ:")
print("   - data/train.jsonlμ— λ” λ§μ€ λ°μ΄ν„° μ¶”κ°€")
print("   - iters κ°’ μ¦κ°€ (1000+)")
print("")
print("3. ν‰κ°€:")
print("   - λ‹¤μ–‘ν• NPC μ‹λ‚λ¦¬μ¤λ΅ ν…μ¤νΈ")
print("")

