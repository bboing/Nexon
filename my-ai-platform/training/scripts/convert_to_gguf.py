#!/usr/bin/env python3
"""
MLX ëª¨ë¸ì„ GGUFë¡œ ë³€í™˜í•˜ì—¬ Ollamaì—ì„œ ì‚¬ìš© ê°€ëŠ¥í•˜ê²Œ ë§Œë“¤ê¸°
"""

import subprocess
import os
from pathlib import Path

def convert_to_gguf():
    """MLX ì–´ëŒ‘í„°ë¥¼ ë³‘í•©í•˜ê³  GGUFë¡œ ë³€í™˜"""
    
    print("ğŸ”„ MLX â†’ GGUF ë³€í™˜ ì‹œì‘")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
    print("   (llama.cppì˜ convert.py í•„ìš”)\n")
    
    

def convert_to_gguf():
    #ê²½ë¡œ ì •ì˜
    base_path = Path(__file__).resolve().parent.parent
    
    # â­ ì´ë¯¸ ë³‘í•©ëœ ëª¨ë¸ ê²½ë¡œ
    merged_model_path = base_path / "models" / "llama-game-npc-mlx-dequantized"
    gguf_output = base_path / "models" / "gguf" / "llama-game-npc.gguf"
    gguf_output.parent.mkdir(parents=True, exist_ok=True)
    # ë³‘í•©ëœ ëª¨ë¸ì´ ìˆëŠ”ì§€ í™•ì¸
    if not merged_model_path.exists():
        print(f"âŒ ë³‘í•©ëœ ëª¨ë¸ì´ ì—†ìŠµë‹ˆë‹¤: {merged_model_path}")
        print("ğŸ’¡ ë¨¼ì € dequantize_mlx.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”!")
        return
    
    print("1ï¸âƒ£  ë³‘í•©ëœ ëª¨ë¸ í™•ì¸ âœ…")
    print(f"   ê²½ë¡œ: {merged_model_path}\n")
    
    # â­ ë°”ë¡œ GGUF ë³€í™˜ ì‹œì‘
    print("2ï¸âƒ£  GGUF ë³€í™˜ ì¤‘...")
    

    # llama.cpp í™•ì¸
    print(f"Path.home(): {Path.home()}")
    llama_cpp_path = Path.home() / "bboing/ollama_model/my-ai-platform/training/llama.cpp"
    if not llama_cpp_path.exists():
        print("âŒ llama.cppê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return
    
    # GGUF ë³€í™˜
    print("ğŸ”„ MLX â†’ GGUF ë³€í™˜ ì‹œì‘")
    convert_cmd = [
        "python",
        str(llama_cpp_path / "convert_hf_to_gguf.py"),
        str(merged_model_path),
        "--outfile", str(gguf_output),
        "--outtype", "f16",  # fp16 precision
    ]
    
    try:
        subprocess.run(convert_cmd, check=True)
        print("âœ… GGUF ë³€í™˜ ì™„ë£Œ!\n")
    except subprocess.CalledProcessError as e:
        print(f"âŒ GGUF ë³€í™˜ ì‹¤íŒ¨: {e}")
        return
    
    print("3ï¸âƒ£  Ollama Modelfile ìƒì„± ì¤‘...\n")
    
    # Ollama Modelfile ìƒì„±
    modelfile_path = Path("../models/Modelfile")
    header = f"FROM {gguf_output.absolute()}\n"
    modelfile_content = """
SYSTEM \"\"\"ë‹¹ì‹ ì€ ì´ ê²Œì„ ì„¸ê³„ì˜ ì‚´ì•„ìˆëŠ” NPCì…ë‹ˆë‹¤.
ë‹¤ìŒ ì›ì¹™ì„ ë°˜ë“œì‹œ ì§€ì¼œ ëŒ€ë‹µí•˜ì„¸ìš”:
1. ì–¸ì–´: ë¬´ì¡°ê±´ ìì—°ìŠ¤ëŸ¬ìš´ 'í•œêµ­ì–´'ë§Œ ì‚¬ìš©í•˜ì„¸ìš”. (ì˜ì–´, í•œì ê¸ˆì§€)
2. íƒœë„: AI ë¹„ì„œì²˜ëŸ¼ ë”±ë”±í•˜ê²Œ êµ´ì§€ ë§ê³ , ë§¡ì€ ì—­í• (Role)ì— ëª°ì…í•˜ì—¬ ì—°ê¸°í•˜ì„¸ìš”.
3. ì§€ì‹: ë‹¹ì‹ ì´ ì•Œê³  ìˆëŠ” ì„¤ì • ë‚´ì—ì„œë§Œ ëŒ€ë‹µí•˜ê³ , ëª¨ë¥´ëŠ” ë‚´ìš©ì€ "ê·¸ê±´ ë‚´ ì•Œ ë°” ì•„ë‹ˆë„¤" í˜¹ì€ "ëª¨ë¥´ê² ëŠ”ë°?"ì™€ ê°™ì´ NPCìŠ¤ëŸ½ê²Œ ê±°ì ˆí•˜ì„¸ìš”. ì—†ëŠ” ì‚¬ì‹¤ì„ ì§€ì–´ë‚´ì§€ ë§ˆì„¸ìš”.
4. í˜•ì‹: ë‹µë³€ì€ ë„ˆë¬´ ê¸¸ì§€ ì•Šê²Œ, ëŒ€í™”í•˜ë“¯ì´ 2~3ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ í•˜ì„¸ìš”.\"\"\"

TEMPLATE \"\"\"{{ if .System }}<|start_header_id|>system<|end_header_id|>

{{ .System }}<|eot_id|>{{ end }}{{ if .User }}<|start_header_id|>user<|end_header_id|>

{{ .User }}<|eot_id|>{{ end }}<|start_header_id|>assistant<|end_header_id|>

{{ .Response }}<|eot_id|>\"\"\"

PARAMETER temperature 0.6

PARAMETER num_ctx 4096

PARAMETER stop "<|start_header_id|>"
PARAMETER stop "<|end_header_id|>"
PARAMETER stop "<|eot_id|>"
"""
    modelfile_content = header + modelfile_content
    modelfile_path.write_text(modelfile_content)
    print(f"âœ… Modelfile ìƒì„±: {modelfile_path}\n")
    
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
    print("âœ… ë³€í™˜ ì™„ë£Œ!")
    print("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
    
    print("ğŸš€ Ollamaì— ë“±ë¡í•˜ê¸°:")
    print(f"   cd {Path('../models').absolute()}")
    print(f"   ollama create game-npc -f Modelfile")
    print()
    print("ğŸ’¬ í…ŒìŠ¤íŠ¸í•˜ê¸°:")
    print("   ollama run game-npc")
    print()
    print("ğŸŒ WebUIì—ì„œ ì‚¬ìš©:")
    print("   http://localhost:8090 ì ‘ì†")
    print("   ëª¨ë¸ ì„ íƒ: game-npc")



if __name__ == "__main__":
    print("\nâš ï¸  ì£¼ì˜: ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” llama.cppê°€ ì„¤ì¹˜ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.\n")
    convert_to_gguf()
